# ğŸ—ï¸ è¯­éŸ³è´¨é‡æ£€æµ‹ç³»ç»Ÿ - å®Œæ•´å·¥ä½œé€»è¾‘

**ç‰ˆæœ¬**: v2.0  
**æ—¥æœŸ**: 2026å¹´1æœˆ27æ—¥  
**ä½œè€…**: Audio Quality Assessment System

---

## ğŸ“– ç›®å½•

1. [ç³»ç»Ÿæ¦‚è§ˆ](#ç³»ç»Ÿæ¦‚è§ˆ)
2. [æ ¸å¿ƒæ¶æ„](#æ ¸å¿ƒæ¶æ„)
3. [æ•°æ®æµè¯¦è§£](#æ•°æ®æµè¯¦è§£)
4. [ç‰¹å¾æå–æœºåˆ¶](#ç‰¹å¾æå–æœºåˆ¶)
5. [æ£€æµ‹å™¨è¯¦è§£](#æ£€æµ‹å™¨è¯¦è§£)
6. [é…ç½®ç³»ç»Ÿ](#é…ç½®ç³»ç»Ÿ)
7. [å®Œæ•´æ‰§è¡Œæµç¨‹](#å®Œæ•´æ‰§è¡Œæµç¨‹)

---

## ç³»ç»Ÿæ¦‚è§ˆ

### è®¾è®¡æ€æƒ³

è¿™æ˜¯ä¸€ä¸ª**åŸºäºå£°å­¦ç‰¹å¾çš„è§„åˆ™å¼•æ“**ï¼Œä¸“é—¨æ£€æµ‹é€šè¯/VoIPéŸ³é¢‘ä¸­çš„è´¨é‡é—®é¢˜ã€‚é‡‡ç”¨**åˆ†å±‚æ£€æµ‹ + åå¤„ç†**æ¶æ„ï¼š

```
éŸ³é¢‘è¾“å…¥ â†’ å¸§åˆ‡åˆ† â†’ ç‰¹å¾æå– â†’ VADè¿‡æ»¤ â†’ å¤šæ£€æµ‹å™¨å¹¶è¡Œ â†’ äº‹ä»¶èšåˆ â†’ æŒç»­æ€§è¿‡æ»¤ â†’ è¾“å‡ºæŠ¥å‘Š
```

### æ ¸å¿ƒèƒ½åŠ›

| æ£€æµ‹ç±»å‹ | åŸç† | å…¸å‹åœºæ™¯ |
|---------|------|---------|
| **å™ªå£°** (Noise) | ZCRã€RMSæ³¢åŠ¨ã€é¢‘è°±æ»šé™ | é£å™ªã€çˆ†éŸ³ã€åº•å™ªçªå¢ |
| **å¡é¡¿** (Dropout) | RMSæä½ + ZCRæä½ | ç½‘ç»œä¸¢åŒ…ã€ç¼“å†²åŒºæ¬ æµ |
| **éŸ³é‡èµ·ä¼** (Volume Fluctuation) | RMSæ–¹å‘åè½¬ | AGCå¤±æ•ˆæ³µåŠ¨ |
| **å˜å£°/å¤±çœŸ** (Distortion) | é¢‘è°±çªå˜ã€å‰Šæ³¢ | ç¼–ç å¤±çœŸã€å›å£°æ¶ˆé™¤é”™è¯¯ |

---

## æ ¸å¿ƒæ¶æ„

### 1. æ¨¡å—åˆ’åˆ†

```
voice_quality_tool/
â”‚
â”œâ”€â”€ analyze_file.py          # å…¥å£1ï¼šç¦»çº¿åˆ†æï¼ˆæ–‡ä»¶ï¼‰
â”œâ”€â”€ analyze_mic.py           # å…¥å£2ï¼šå®æ—¶åˆ†æï¼ˆéº¦å…‹é£ï¼‰
â”œâ”€â”€ calibrate.py             # å…¥å£3ï¼šè®¾å¤‡æ ¡å‡†
â”‚
â”œâ”€â”€ analyzer/                # æ ¸å¿ƒåˆ†æå¼•æ“
â”‚   â”œâ”€â”€ analyzer.py          # ä¸»è°ƒåº¦å™¨ï¼ˆåè°ƒæ‰€æœ‰æ£€æµ‹å™¨ï¼‰
â”‚   â”œâ”€â”€ features.py          # ç‰¹å¾æå–ï¼ˆ8ä¸ªå£°å­¦ç‰¹å¾ï¼‰
â”‚   â”œâ”€â”€ frame.py             # å¸§åˆ‡åˆ†ä¸æ—¶é—´çº¿ç®¡ç†
â”‚   â”œâ”€â”€ vad.py               # è¯­éŸ³æ´»åŠ¨æ£€æµ‹ï¼ˆè¿‡æ»¤éäººå£°ï¼‰
â”‚   â”œâ”€â”€ result.py            # ç»“æœèšåˆä¸è¾“å‡º
â”‚   â”‚
â”‚   â””â”€â”€ detectors/           # æ£€æµ‹å™¨é›†åˆï¼ˆæ’ä»¶å¼ï¼‰
â”‚       â”œâ”€â”€ base.py          # åŸºç±» + å·¥å…·å‡½æ•°
â”‚       â”œâ”€â”€ noise.py         # å™ªå£°æ£€æµ‹å™¨
â”‚       â”œâ”€â”€ dropout.py       # å¡é¡¿æ£€æµ‹å™¨
â”‚       â”œâ”€â”€ volume.py        # éŸ³é‡æ³¢åŠ¨æ£€æµ‹å™¨
â”‚       â”œâ”€â”€ distortion.py    # å¤±çœŸæ£€æµ‹å™¨
â”‚       â””â”€â”€ enhanced_distortion.py  # å¢å¼ºå¤±çœŸæ£€æµ‹ï¼ˆå¯é€‰ï¼‰
â”‚
â””â”€â”€ docs/                    # æŠ€æœ¯æ–‡æ¡£
    â”œâ”€â”€ DETECTION_PRINCIPLES.md    # æ£€æµ‹åŸç†è¯¦è§£
    â””â”€â”€ CLEAN_SPEECH_CONFIG.md     # é…ç½®é¢„è®¾
```

### 2. ç±»å…³ç³»å›¾

```
Analyzer (ä¸»è°ƒåº¦å™¨)
    â”‚
    â”œâ”€â”€ FrameGenerator (å¸§ç”Ÿæˆå™¨)
    â”‚       â””â”€â”€ Frame (æ•°æ®å®¹å™¨)
    â”‚
    â”œâ”€â”€ FeatureExtractor (ç‰¹å¾æå–)
    â”‚       â””â”€â”€ Features Dict (8ä¸ªç‰¹å¾)
    â”‚
    â”œâ”€â”€ VAD (è¯­éŸ³æ´»åŠ¨æ£€æµ‹)
    â”‚
    â”œâ”€â”€ NoiseDetector â”€â”€â”€â”€â”
    â”œâ”€â”€ DropoutDetector â”€â”€â”€â”¤
    â”œâ”€â”€ VolumeDetector â”€â”€â”€â”€â”¼â”€â”€ ç»§æ‰¿ BaseDetector
    â””â”€â”€ DistortionDetector â”˜
            â”‚
            â””â”€â”€ DetectionEvent (äº‹ä»¶å¯¹è±¡)
                    â”‚
                    â””â”€â”€ AnalysisResult (èšåˆç»“æœ)
```

---

## æ•°æ®æµè¯¦è§£

### å®Œæ•´å¤„ç†æµç¨‹

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  éŸ³é¢‘æ–‡ä»¶è¾“å…¥    â”‚ (audio.wav, 16kHz/44.1kHz)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. éŸ³é¢‘åŠ è½½      â”‚ scipy.io.wavfile.read()
â”‚    - è½¬å•å£°é“    â”‚ å¦‚æœæ˜¯ç«‹ä½“å£° â†’ åªå–å·¦å£°é“
â”‚    - å½’ä¸€åŒ–      â”‚ è½¬æ¢ä¸º [-1, 1] æµ®ç‚¹æ•°
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. å¸§åˆ‡åˆ†        â”‚ frame_generator()
â”‚    å¸§å¤§å°: 25ms  â”‚ frame_size = sample_rate * 0.025
â”‚    è·³è·ƒ: 10ms    â”‚ hop_size = sample_rate * 0.010
â”‚                  â”‚ â†’ å¸§é‡å ç‡ 60%
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. ç‰¹å¾æå–      â”‚ extract_features(frame)
â”‚    æ¯å¸§æå–8ä¸ª   â”‚ â†’ Features Dict
â”‚    å£°å­¦ç‰¹å¾      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. VADè¿‡æ»¤      â”‚ is_voice_active(features)
â”‚    åˆ¤æ–­æ˜¯å¦äººå£°  â”‚ åŸºäº RMS + Centroid + ZCR
â”‚    (å¯é€‰)        â”‚ â†’ True/False
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 5. å¹¶è¡Œæ£€æµ‹      â”‚ 4ä¸ªæ£€æµ‹å™¨åŒæ—¶è¿è¡Œ
â”‚    æ¯ä¸ªæ£€æµ‹å™¨    â”‚ detector.detect(features, frame)
â”‚    ç‹¬ç«‹åˆ¤æ–­      â”‚ â†’ DetectionEvent / None
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 6. äº‹ä»¶èšåˆ      â”‚ result.add_event(event)
â”‚    æ”¶é›†æ‰€æœ‰äº‹ä»¶  â”‚ â†’ List[DetectionEvent]
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 7. åå¤„ç†        â”‚ result.finalize()
â”‚    - åˆå¹¶ç›¸é‚»    â”‚ gap < 150ms â†’ åˆå¹¶
â”‚    - è¿‡æ»¤çŸ­äº‹ä»¶  â”‚ duration < min_duration â†’ åˆ é™¤
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 8. è¾“å‡ºæŠ¥å‘Š      â”‚ result.to_json() / print_summary()
â”‚    JSONæ ¼å¼      â”‚ {noise: {...}, dropout: {...}, ...}
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### å…³é”®æ—¶é—´å‚æ•°

| å‚æ•° | å€¼ | è¯´æ˜ |
|------|----|----|
| **å¸§å¤§å°** | 25ms | è¶³å¤ŸçŸ­ä»¥æ•æ‰ç¬æ€ï¼Œè¶³å¤Ÿé•¿ä»¥è®¡ç®—é¢‘è°± |
| **å¸§è·³è·ƒ** | 10ms | 60%é‡å ï¼Œæé«˜æ—¶é—´åˆ†è¾¨ç‡ |
| **åˆå¹¶é—´éš”** | 150ms | ä¸¤ä¸ªäº‹ä»¶é—´éš”<150msè§†ä¸ºåŒä¸€é—®é¢˜ |
| **æœ€å°æŒç»­æ—¶é—´** | 50-600ms | æŒ‰é—®é¢˜ç±»å‹å·®å¼‚åŒ–ï¼ˆè§ä¸‹ï¼‰ |

**å·®å¼‚åŒ–æŒç»­æ€§é˜ˆå€¼**ï¼ˆåŸºäºäººè€³æ„ŸçŸ¥ç ”ç©¶ï¼‰ï¼š
```python
min_event_duration = {
    "dropout": 0.05,              # 50ms - æœ€æ•æ„Ÿ
    "voice_distortion": 0.12,     # 120ms
    "noise": 0.15,                # 150ms
    "volume_fluctuation": 0.25,   # 250ms - æœ€ä¸æ•æ„Ÿ
}
```

---

## ç‰¹å¾æå–æœºåˆ¶

### æ ¸å¿ƒç‰¹å¾ï¼ˆ5ä¸ªï¼‰

æ¯å¸§æå–ä»¥ä¸‹5ä¸ªåŸºç¡€ç‰¹å¾ï¼š

#### 1. **RMS (Root Mean Square) - èƒ½é‡**
```python
rms = sqrt(mean(samples^2))
```
- **ç”¨é€”**: éŸ³é‡æ£€æµ‹ã€é™éŸ³æ£€æµ‹
- **èŒƒå›´**: 0.0 ~ 1.0ï¼ˆå½’ä¸€åŒ–éŸ³é¢‘ï¼‰
- **äººå£°å…¸å‹å€¼**: 0.05 ~ 0.3

#### 2. **Zero Crossing Rate (ZCR) - é›¶äº¤å‰ç‡**
```python
zcr = count(sign_change) / len(samples)
```
- **ç”¨é€”**: åŒºåˆ†å™ªå£°ï¼ˆé«˜ZCRï¼‰vs äººå£°ï¼ˆä¸­ç­‰ZCRï¼‰
- **èŒƒå›´**: 0.0 ~ 0.5
- **äººå£°å…¸å‹å€¼**: 0.05 ~ 0.15
- **å™ªå£°å…¸å‹å€¼**: > 0.15

#### 3. **Spectral Centroid - é¢‘è°±è´¨å¿ƒ**
```python
centroid = sum(frequencies * fft_magnitudes) / sum(fft_magnitudes)
```
- **ç”¨é€”**: éŸ³è‰²æ£€æµ‹ï¼ˆå°–é”/ä½æ²‰ï¼‰
- **èŒƒå›´**: 0 ~ sample_rate/2 (Hz)
- **äººå£°å…¸å‹å€¼**: 200 ~ 2000 Hz
- **æœºæ¢°å£°**: > 3000 Hz

#### 4. **Spectral Bandwidth - é¢‘è°±å¸¦å®½**
```python
bandwidth = sqrt(sum((freqs - centroid)^2 * fft) / sum(fft))
```
- **ç”¨é€”**: æ£€æµ‹é¢‘ç‡åˆ†å¸ƒå¼‚å¸¸
- **ç¼–ç å¤±çœŸ**: å¸¦å®½çªç„¶å˜çª„

#### 5. **Spectral Flux - é¢‘è°±æµé‡**
```python
flux = sqrt(sum((fft_current - fft_previous)^2))
```
- **ç”¨é€”**: æ£€æµ‹é¢‘è°±çªå˜ï¼ˆå¸§é—´å˜åŒ–ï¼‰
- **ç”¨äº**: å˜å£°ã€ç¼–ç å¤±çœŸã€å›å£°æ¶ˆé™¤é”™è¯¯

### ç¬¬1é˜¶æ®µæ‰©å±•ç‰¹å¾ï¼ˆ3ä¸ªï¼‰

ç”¨äºæé«˜ç¬æ€æ£€æµ‹å‡†ç¡®æ€§ï¼š

#### 6. **Peak-to-Peak - å³°å³°å€¼**
```python
p2p = max(samples) - min(samples)
```
- **ç”¨é€”**: å‰Šæ³¢æ£€æµ‹ï¼ˆaudio clippingï¼‰
- **é˜ˆå€¼**: > 1.8 è§†ä¸ºå‰Šæ³¢ï¼ˆæ»¡å¹…ä¸º2.0ï¼‰

#### 7. **Spectral Rolloff - é¢‘è°±æ»šé™**
```python
rolloff_freq = freq where 95% energy is below
```
- **ç”¨é€”**: æ£€æµ‹é£å™ªã€é«˜é¢‘å™ªå£°
- **é˜ˆå€¼**: > 3000 Hz è§†ä¸ºé«˜é¢‘å™ªå£°

#### 8. **RMS Percentile (P95) - RMS 95åˆ†ä½æ•°**
```python
rms_p95 = percentile(sub_frame_rms_list, 95)
```
- **ç”¨é€”**: æ•æ‰ç¬æ€çˆ†éŸ³ï¼ˆæ¯”å‡å€¼æ›´æ•æ„Ÿï¼‰
- **ä¼˜åŠ¿**: ä¸è¢«å¹³å‡å€¼æ©ç›–

### ç¬¬2é˜¶æ®µç‰¹å¾ï¼ˆå¯é€‰ï¼‰

#### 9. **MFCC (Mel-Frequency Cepstral Coefficients)**
```python
mfcc = librosa.feature.mfcc(samples, sr, n_mfcc=13)
```
- **ç”¨é€”**: éŸ³è‰²ç‰¹å¾ã€éº¦å…‹é£å“åº”å·®å¼‚
- **ä¾èµ–**: éœ€è¦ `librosa` åº“
- **é»˜è®¤**: ç¦ç”¨ï¼ˆå‡å°‘ä¾èµ–ï¼‰

---

## æ£€æµ‹å™¨è¯¦è§£

### 1. NoiseDetectorï¼ˆå™ªå£°æ£€æµ‹å™¨ï¼‰

#### æ£€æµ‹åŸç†

**æ–¹æ³•1: æŒä¹…æ€§èƒŒæ™¯å™ªå£°**ï¼ˆé»˜è®¤ç¦ç”¨ï¼‰
```python
if zcr > 0.15:  # é«˜é›¶äº¤å‰ç‡
    â†’ æŠ¥å‘Šå™ªå£°
```

**æ–¹æ³•2: çªå‘å™ªå£°ï¼ˆçˆ†éŸ³ï¼‰**
```python
if (rms_increase > 30%) or (rms_p95 > rms * 1.5):
    â†’ æŠ¥å‘Šçˆ†éŸ³
```

**æ–¹æ³•3: é£å™ªæ£€æµ‹**
```python
if spectral_rolloff > 3000 Hz:  # é«˜é¢‘èƒ½é‡è¿‡å¤š
    â†’ æŠ¥å‘Šé£å™ª
```

#### é…ç½®å‚æ•°
```python
{
    "detect_background_noise": False,  # é»˜è®¤åªæ£€æµ‹çªå‘å™ªå£°
    "noise_zcr_threshold": 0.15,
    "burst_spike_threshold": 0.3,      # RMSå¢å¹…>30%
    "spectral_rolloff_threshold": 3000,
}
```

#### å…¸å‹è¾“å‡º
```json
{
  "event_type": "noise",
  "start_time": 12.35,
  "end_time": 13.10,
  "confidence": 0.85,
  "details": {
    "reason": "noise_burst_with_transient",
    "rms_increase_ratio": 0.45,
    "rms_p95": 0.12
  }
}
```

---

### 2. DropoutDetectorï¼ˆå¡é¡¿æ£€æµ‹å™¨ï¼‰

#### æ£€æµ‹åŸç†

æ£€æµ‹"æœ‰å£° â†’ æ— å£° â†’ æœ‰å£°"çš„çªå˜ï¼ˆçŠ¶æ€æœºï¼‰ï¼š

```python
is_silence = (rms < 0.01) and (zcr < 0.05)

if is_silence and not prev_is_silence:
    â†’ æŠ¥å‘Šå¡é¡¿ï¼ˆè¾¹ç•Œè§¦å‘ï¼‰
```

**ä¸ºä»€ä¹ˆåªæ£€æµ‹è¾¹ç•Œï¼Ÿ**
- æŒç»­é™éŸ³ â‰  å¡é¡¿ï¼ˆå¯èƒ½æ˜¯è¯´è¯è€…åœé¡¿ï¼‰
- å¡é¡¿ = çªç„¶çš„ã€éé¢„æœŸçš„é™éŸ³
- åªåœ¨**è¿›å…¥é™éŸ³æ—¶**æŠ¥å‘Šä¸€æ¬¡

#### ç‰¹æ®Šå¤„ç†

**ä¸å—VADè¿‡æ»¤**ï¼š
```python
# Dropoutæ£€æµ‹å³ä½¿VAD=Falseä¹Ÿè¿è¡Œ
dropout_event = self.dropout_detector.detect(
    features, frame, is_voice_active=voice_active
)
```
**åŸå› **: å¡é¡¿æœ¬èº«å°±æ˜¯å¼‚å¸¸é™éŸ³ï¼Œä¸åº”è¢«VADè¿‡æ»¤æ‰

#### é…ç½®å‚æ•°
```python
{
    "silence_rms_threshold": 0.01,     # æä½èƒ½é‡
    "dropout_zcr_threshold": 0.05,     # æä½é›¶äº¤å‰ç‡
    "min_event_duration": {"dropout": 0.05}  # 50ms
}
```

#### å…¸å‹è¾“å‡º
```json
{
  "event_type": "dropout",
  "start_time": 45.80,
  "end_time": 46.40,
  "confidence": 0.9,
  "details": {
    "reason": "sudden_silence_dropout",
    "rms": 0.003,
    "threshold": 0.01
  }
}
```

---

### 3. VolumeDetectorï¼ˆéŸ³é‡æ³¢åŠ¨æ£€æµ‹å™¨ï¼‰

#### æ£€æµ‹åŸç†

**åŒºåˆ†ä¸¤ç§åœºæ™¯**ï¼š

1. **âŒ ä¸æ£€æµ‹ï¼šè¯´è¯è€…åˆ‡æ¢**ï¼ˆå•å‘å˜åŒ–ï¼‰
   ```
   å° â†’ å¤§ â†’ å¤§  (æŒç»­ä¸Šå‡)
   å¤§ â†’ å° â†’ å°  (æŒç»­ä¸‹é™)
   ```

2. **âœ… æ£€æµ‹ï¼šAGCæ³µåŠ¨**ï¼ˆæ–¹å‘åè½¬ï¼‰
   ```
   å¤§ â†’ å° â†’ å¤§  (æ³µåŠ¨)
   å° â†’ å¤§ â†’ å°  (æ³µåŠ¨)
   ```

**å®ç°ï¼ˆæ–¹å‘åè½¬æ£€æµ‹ï¼‰**ï¼š
```python
direction_change = (curr_rms - last_rms) * (last_rms - prev_rms)

if direction_change < 0:  # æ–¹å‘åè½¬
    â†’ æŠ¥å‘ŠAGCæ³µåŠ¨
```

#### é…ç½®å‚æ•°
```python
{
    "rms_change_threshold": 0.5,  # 50%å˜åŒ–
    "min_event_duration": {"volume_fluctuation": 0.25}  # 250ms
}
```

#### å…¸å‹è¾“å‡º
```json
{
  "event_type": "volume_fluctuation",
  "start_time": 28.02,
  "end_time": 28.60,
  "confidence": 0.75,
  "details": {
    "reason": "agc_pumping",
    "rms_ratio": 1.8,
    "pattern": "direction_reversal"
  }
}
```

---

### 4. DistortionDetectorï¼ˆå¤±çœŸæ£€æµ‹å™¨ï¼‰

#### æ£€æµ‹åŸç†

**ä¸¤ç§å·¥ä½œæ¨¡å¼**ï¼š

**æ¨¡å¼1: åŸºäºæ ¡å‡†åŸºçº¿**ï¼ˆæ¨èï¼‰
```python
if baselineå­˜åœ¨:
    flux_ratio = current_flux / baseline_flux
    if flux_ratio > 2.0:  # è¶…è¿‡åŸºçº¿2å€
        â†’ æŠ¥å‘Šé¢‘è°±çªå˜
    
    centroid_shift = |current_centroid - baseline_centroid|
    if centroid_shift > 500 Hz:
        â†’ æŠ¥å‘ŠéŸ³è‰²å˜åŒ–
```

**æ¨¡å¼2: ç›¸é‚»å¸§å¯¹æ¯”**ï¼ˆå…¼å®¹æ¨¡å¼ï¼‰
```python
else:
    if spectral_flux > 0.2:
        â†’ æŠ¥å‘Šé¢‘è°±çªå˜
    
    if |centroid - prev_centroid| > 500:
        â†’ æŠ¥å‘ŠéŸ³è‰²å˜åŒ–
```

**å‰Šæ³¢æ£€æµ‹**ï¼ˆä¼˜å…ˆçº§æœ€é«˜ï¼‰ï¼š
```python
if peak_to_peak > 1.8:  # æ¥è¿‘æ»¡å¹…2.0
    â†’ æŠ¥å‘ŠéŸ³é¢‘å‰Šæ³¢
```

#### é…ç½®å‚æ•°
```python
{
    "spectral_flux_threshold": 0.2,
    "centroid_shift_threshold": 500.0,  # Hz
    "bandwidth_spike_threshold": 1.5,
    "peak_to_peak_threshold": 1.8,
    "min_event_duration": {"voice_distortion": 0.12}  # 120ms
}
```

#### å…¸å‹è¾“å‡º
```json
{
  "event_type": "voice_distortion",
  "start_time": 15.20,
  "end_time": 15.90,
  "confidence": 0.88,
  "details": {
    "reason": "high_spectral_flux_vs_baseline",
    "spectral_flux": 0.45,
    "baseline_flux": 0.18,
    "flux_ratio": 2.5
  }
}
```

---

## é…ç½®ç³»ç»Ÿ

### é»˜è®¤é…ç½®ï¼ˆDEFAULT_CONFIGï¼‰

é€‚ç”¨äº**ç”µè¯/VoIPè´¨é‡**æ£€æµ‹ï¼š

```python
DEFAULT_CONFIG = {
    # VAD
    "enable_vad": True,
    "vad_min_rms": 0.02,
    "vad_max_rms": 1.0,
    "vad_min_centroid": 80,
    "vad_max_centroid": 3000,
    "vad_min_zcr": 0.03,
    "vad_max_zcr": 0.18,
    
    # æŒç»­æ€§é˜ˆå€¼ï¼ˆå·®å¼‚åŒ–ï¼‰
    "min_event_duration": {
        "noise": 0.15,              # 150ms
        "dropout": 0.05,            # 50ms
        "volume_fluctuation": 0.25, # 250ms
        "voice_distortion": 0.12,   # 120ms
    },
    
    # å™ªå£°æ£€æµ‹
    "detect_background_noise": False,
    "noise_zcr_threshold": 0.15,
    "burst_spike_threshold": 0.3,
    "spectral_rolloff_threshold": 3000,
    
    # å¡é¡¿æ£€æµ‹
    "silence_rms_threshold": 0.01,
    "dropout_zcr_threshold": 0.05,
    
    # éŸ³é‡æ³¢åŠ¨
    "rms_change_threshold": 0.5,
    
    # å¤±çœŸæ£€æµ‹
    "spectral_flux_threshold": 0.2,
    "centroid_shift_threshold": 500.0,
    "bandwidth_spike_threshold": 1.5,
    "peak_to_peak_threshold": 1.8,
}
```

### å¹²å‡€è¯­éŸ³é…ç½®ï¼ˆCLEAN_SPEECH_CONFIGï¼‰

é€‚ç”¨äº**å½•éŸ³å®¤/æ’­å®¢**é«˜è´¨é‡éŸ³é¢‘ï¼ˆæ”¾å®½4å€ï¼‰ï¼š

```python
CLEAN_SPEECH_CONFIG = {
    **DEFAULT_CONFIG,
    "min_event_duration": {
        "noise": 0.60,              # 600msï¼ˆ4å€ï¼‰
        "dropout": 0.20,            # 200msï¼ˆ4å€ï¼‰
        "volume_fluctuation": 1.00, # 1000msï¼ˆ4å€ï¼‰
        "voice_distortion": 0.50,   # 500msï¼ˆ4å€ï¼‰
    },
    "spectral_rolloff_threshold": 4000,  # æé«˜
    "peak_to_peak_threshold": 1.9,       # æ›´ä¸¥æ ¼
}
```

### è®¾å¤‡æ ¡å‡†é…ç½®

é€šè¿‡ `calibrate.py` ç”Ÿæˆï¼š

```json
// device_profile.json
{
  "device_name": "AirPods Pro",
  "calibration_date": "2026-01-27",
  "baseline_stats": {
    "rms_mean": 0.08,
    "centroid_mean": 850.5,
    "spectral_flux_mean": 0.12,
    ...
  },
  "recommended_config": {
    "silence_rms_threshold": 0.015,  // åŸºäºè®¾å¤‡åº•å™ª
    "noise_zcr_threshold": 0.18,     // åŸºäºç¯å¢ƒå™ªå£°
    ...
  }
}
```

---

## å®Œæ•´æ‰§è¡Œæµç¨‹

### ç¦»çº¿åˆ†æï¼ˆanalyze_file.pyï¼‰

```bash
python analyze_file.py audio.wav --output report.json
```

**æ‰§è¡Œæ­¥éª¤**ï¼š

1. **åŠ è½½éŸ³é¢‘**
   ```python
   sample_rate, data = wavfile.read("audio.wav")
   data = data / (2**15)  # å½’ä¸€åŒ–
   ```

2. **é€‰æ‹©é…ç½®**
   ```python
   if mode == 'clean-speech':
       config = CLEAN_SPEECH_CONFIG
   else:
       config = DEFAULT_CONFIG
   ```

3. **å¯é€‰ï¼šåŠ è½½è®¾å¤‡é…ç½®**
   ```python
   if profile_path:
       profile = json.load(profile_path)
       config.update(profile["recommended_config"])
   ```

4. **åˆ›å»ºåˆ†æå™¨**
   ```python
   analyzer = Analyzer(config=config)
   ```

5. **ç”Ÿæˆå¸§æµ**
   ```python
   frame_size = sample_rate * 0.025  # 25ms
   hop_size = sample_rate * 0.010     # 10ms
   frames = frame_generator(data, sample_rate, frame_size, hop_size)
   ```

6. **æ‰§è¡Œåˆ†æ**
   ```python
   result = analyzer.analyze_frames(frames)
   ```
   å†…éƒ¨å¾ªç¯ï¼š
   ```python
   for frame in frames:
       # 1. æå–ç‰¹å¾
       features = extract_features(frame, prev_frame)
       
       # 2. VADè¿‡æ»¤
       voice_active = is_voice_active(features, config)
       
       # 3. æ£€æµ‹å™¨è¿è¡Œ
       for detector in [noise, dropout, volume, distortion]:
           event = detector.detect(features, frame, prev_features)
           if event:
               result.add_event(event)
   ```

7. **åå¤„ç†**
   ```python
   result.finalize(min_duration_dict={...})
   # - åˆå¹¶ç›¸é‚»äº‹ä»¶ï¼ˆgap < 150msï¼‰
   # - è¿‡æ»¤çŸ­äº‹ä»¶ï¼ˆæŒ‰ç±»å‹å·®å¼‚åŒ–é˜ˆå€¼ï¼‰
   ```

8. **è¾“å‡ºç»“æœ**
   ```python
   result.print_summary()  # æ§åˆ¶å°
   result.to_json_string() # JSONæ ¼å¼
   ```

### å®æ—¶åˆ†æï¼ˆanalyze_mic.pyï¼‰

```bash
python analyze_mic.py 10  # å½•åˆ¶10ç§’
```

**æ‰§è¡Œæ­¥éª¤**ï¼š

1. **åˆå§‹åŒ–PyAudio**
   ```python
   p = pyaudio.PyAudio()
   stream = p.open(format=pyaudio.paInt16, 
                   channels=1, 
                   rate=16000, 
                   input=True)
   ```

2. **å®æ—¶å½•åˆ¶ + åˆ†æ**
   ```python
   for i in range(num_chunks):
       # è¯»å–éŸ³é¢‘å—ï¼ˆä¾‹å¦‚100msï¼‰
       chunk = stream.read(chunk_size)
       
       # è½¬æ¢ä¸ºå¸§
       frame = Frame(samples=chunk, ...)
       
       # æå–ç‰¹å¾
       features = extract_features(frame, prev_frame)
       
       # æ£€æµ‹
       for detector in detectors:
           event = detector.detect(features, frame)
           if event:
               print(f"[{event.start_time:.2f}s] {event.event_type}")
   ```

3. **å®æ—¶è¾“å‡º**
   ```
   [2.35s] noise (burst)
   [5.80s] dropout (silence)
   [8.02s] volume_fluctuation (agc_pumping)
   ```

### è®¾å¤‡æ ¡å‡†ï¼ˆcalibrate.pyï¼‰

```bash
python calibrate.py baseline.wav --output device_profile.json
```

**æ‰§è¡Œæ­¥éª¤**ï¼š

1. **åŠ è½½åŸºçº¿éŸ³é¢‘**ï¼ˆå¹²å‡€çš„äººå£°æ ·æœ¬ï¼‰
   ```python
   baseline_audio = load_audio("baseline.wav")
   ```

2. **æå–æ‰€æœ‰å¸§ç‰¹å¾**
   ```python
   frames = frame_generator(baseline_audio, ...)
   all_features = [extract_features(f) for f in frames]
   ```

3. **è®¡ç®—ç»Ÿè®¡ä¿¡æ¯**
   ```python
   baseline = compute_baseline_stats(all_features)
   # åŒ…å«ï¼šmean, std, percentiles for all features
   ```

4. **ç”Ÿæˆæ¨èé˜ˆå€¼**
   ```python
   recommended_config = {
       "silence_rms_threshold": baseline["rms_p10"] * 0.5,
       "noise_zcr_threshold": baseline["zcr_mean"] + 2*baseline["zcr_std"],
       ...
   }
   ```

5. **ä¿å­˜é…ç½®**
   ```python
   json.dump({
       "baseline_stats": baseline,
       "recommended_config": recommended_config
   }, file)
   ```

---

## VADï¼ˆè¯­éŸ³æ´»åŠ¨æ£€æµ‹ï¼‰è¯¦è§£

### ä½œç”¨

è¿‡æ»¤æ‰**éäººå£°æ®µè½**ï¼ˆèƒŒæ™¯å™ªéŸ³ã€é™éŸ³ï¼‰ï¼Œé¿å…è¯¯æŠ¥ã€‚

### åˆ¤æ–­é€»è¾‘

ç»¼åˆ3ä¸ªç‰¹å¾æŠ•ç¥¨ï¼ˆè‡³å°‘æ»¡è¶³2ä¸ªï¼‰ï¼š

```python
def is_voice_active(features, config) -> bool:
    rms = features["rms"]
    centroid = features["spectral_centroid"]
    zcr = features["zero_crossing_rate"]
    
    # æ¡ä»¶1: èƒ½é‡åœ¨åˆç†èŒƒå›´
    rms_ok = 0.02 < rms < 1.0
    
    # æ¡ä»¶2: é¢‘è°±ä¸­å¿ƒåœ¨äººå£°é¢‘æ®µ
    centroid_ok = 80 < centroid < 3000  # Hz
    
    # æ¡ä»¶3: é›¶äº¤å‰ç‡é€‚ä¸­
    zcr_ok = 0.03 < zcr < 0.18
    
    # æŠ•ç¥¨ï¼šè‡³å°‘2ä¸ªæ¡ä»¶æ»¡è¶³
    vote_count = sum([rms_ok, centroid_ok, zcr_ok])
    return vote_count >= 2
```

### ç‰¹æ®Šå¤„ç†

**Dropoutæ£€æµ‹å™¨ä¸å—VADé™åˆ¶**ï¼š
```python
# å³ä½¿VAD=Falseï¼Œä¹Ÿæ£€æµ‹dropout
dropout_event = self.dropout_detector.detect(
    features, frame, is_voice_active=voice_active
)

# å…¶ä»–æ£€æµ‹å™¨å—VADé™åˆ¶
if not voice_active:
    continue  # è·³è¿‡éäººå£°æ®µ
```

**åŸå› **: å¡é¡¿æœ¬èº«å°±æ˜¯å¼‚å¸¸çš„æ— å£°/é™éŸ³ï¼Œä¸åº”è¢«VADè¿‡æ»¤ã€‚

---

## åå¤„ç†æœºåˆ¶

### 1. åˆå¹¶ç›¸é‚»äº‹ä»¶

```python
def merge_adjacent_events(events, gap_threshold=0.15):
    """
    å¦‚æœä¸¤ä¸ªäº‹ä»¶é—´éš” < 150msï¼Œè§†ä¸ºåŒä¸€é—®é¢˜
    """
    merged = []
    for event in sorted(events, key=lambda e: e.start_time):
        if merged and event.start_time - merged[-1].end_time < 0.15:
            # åˆå¹¶ï¼šæ‰©å±•end_time
            merged[-1].end_time = max(merged[-1].end_time, event.end_time)
        else:
            merged.append(event)
    return merged
```

**ç¤ºä¾‹**ï¼š
```
åŸå§‹äº‹ä»¶:
  [12.30s - 12.45s] noise
  [12.50s - 12.65s] noise  â† é—´éš”50ms

åˆå¹¶å:
  [12.30s - 12.65s] noise
```

### 2. è¿‡æ»¤çŸ­äº‹ä»¶

```python
def filter_short_events(events, min_duration_dict):
    """
    æ ¹æ®é—®é¢˜ç±»å‹ä½¿ç”¨ä¸åŒçš„æœ€å°æŒç»­æ—¶é—´
    """
    filtered = []
    for event in events:
        min_dur = min_duration_dict.get(event.event_type, 0.3)
        if event.duration >= min_dur:
            filtered.append(event)
    return filtered
```

**ç¤ºä¾‹**ï¼ˆdropout: 50msé˜ˆå€¼ï¼‰ï¼š
```
åŸå§‹äº‹ä»¶:
  [5.20s - 5.24s] dropout  â† 40ms (å¤ªçŸ­)
  [5.80s - 5.92s] dropout  â† 120ms (ä¿ç•™)

è¿‡æ»¤å:
  [5.80s - 5.92s] dropout
```

---

## è¾“å‡ºæ ¼å¼

### JSONè¾“å‡º

```json
{
  "noise": {
    "count": 2,
    "events": [
      {
        "start": 12.35,
        "end": 13.10,
        "confidence": 0.85,
        "details": {
          "reason": "noise_burst_with_transient",
          "rms_increase_ratio": 0.45
        }
      },
      {
        "start": 28.02,
        "end": 28.60,
        "confidence": 0.72,
        "details": {
          "reason": "high_frequency_noise_windnoise",
          "spectral_rolloff": 3500.5
        }
      }
    ]
  },
  "dropout": {
    "count": 1,
    "events": [
      {
        "start": 45.80,
        "end": 46.40,
        "confidence": 0.9,
        "details": {
          "reason": "sudden_silence_dropout",
          "rms": 0.003
        }
      }
    ]
  },
  "volume_fluctuation": {
    "count": 0,
    "events": []
  },
  "voice_distortion": {
    "count": 1,
    "events": [
      {
        "start": 15.20,
        "end": 15.90,
        "confidence": 0.88,
        "details": {
          "reason": "audio_clipping",
          "peak_to_peak": 1.92
        }
      }
    ]
  }
}
```

### æ§åˆ¶å°è¾“å‡º

```
============================================================
VOICE QUALITY ANALYSIS REPORT
============================================================
Total duration analyzed: 60.00s
Total frames: 6000

âŒ NOISE: 2 issue(s)
   [12.35s - 13.10s]
   [28.02s - 28.60s]

âŒ DROPOUT: 1 issue(s)
   [45.80s - 46.40s]

âœ“ VOLUME_FLUCTUATION: OK

âŒ VOICE_DISTORTION: 1 issue(s)
   [15.20s - 15.90s]

============================================================
```

---

## æ€§èƒ½æŒ‡æ ‡

### è®¡ç®—å¤æ‚åº¦

| æ“ä½œ | å¤æ‚åº¦ | è¯´æ˜ |
|------|--------|------|
| å¸§åˆ‡åˆ† | O(N) | N = æ ·æœ¬æ•° |
| ç‰¹å¾æå–ï¼ˆæ¯å¸§ï¼‰ | O(F log F) | F = å¸§å¤§å°ï¼ˆFFTï¼‰ |
| æ£€æµ‹å™¨ï¼ˆæ¯å¸§ï¼‰ | O(1) | ç®€å•é˜ˆå€¼åˆ¤æ–­ |
| åå¤„ç† | O(E log E) | E = äº‹ä»¶æ•°ï¼ˆæ’åºï¼‰ |
| **æ€»è®¡** | **O(N log F)** | çº¿æ€§å¤æ‚åº¦ |

### å®æµ‹æ€§èƒ½

- **ç¦»çº¿åˆ†æ**: ~0.1x å®æ—¶ï¼ˆ10ç§’éŸ³é¢‘â†’1ç§’å¤„ç†ï¼‰
- **å®æ—¶åˆ†æ**: å»¶è¿Ÿ < 50msï¼ˆæ»¡è¶³å®æ—¶éœ€æ±‚ï¼‰
- **å†…å­˜å ç”¨**: < 50MBï¼ˆä¸å«éŸ³é¢‘æ•°æ®ï¼‰

---

## æ‰©å±•æ€§è®¾è®¡

### 1. æ’ä»¶å¼æ£€æµ‹å™¨

**æ·»åŠ æ–°æ£€æµ‹å™¨**åªéœ€3æ­¥ï¼š

```python
# Step 1: ç»§æ‰¿BaseDetector
from .base import BaseDetector, DetectionEvent

class MyNewDetector(BaseDetector):
    def __init__(self, config=None):
        super().__init__(config)
        self.my_threshold = config.get("my_threshold", 0.5)
    
    # Step 2: å®ç°detectæ–¹æ³•
    def detect(self, features, frame, prev_features=None, is_voice_active=True):
        if features["rms"] > self.my_threshold:
            return DetectionEvent(
                event_type="my_new_problem",
                start_time=frame.start_time,
                end_time=frame.end_time,
                confidence=0.8
            )
        return None

# Step 3: åœ¨Analyzerä¸­æ³¨å†Œ
class Analyzer:
    def __init__(self, config=None):
        ...
        self.my_detector = MyNewDetector(config=self.config)
    
    def analyze_frames(self, frames):
        ...
        my_event = self.my_detector.detect(features, frame)
        if my_event:
            result.add_event(my_event)
```

### 2. é…ç½®é©±åŠ¨

æ‰€æœ‰é˜ˆå€¼éƒ½é€šè¿‡é…ç½®æ–‡ä»¶æ§åˆ¶ï¼Œæ— éœ€ä¿®æ”¹ä»£ç ï¼š

```python
custom_config = {
    **DEFAULT_CONFIG,
    "my_threshold": 0.8,  # è‡ªå®šä¹‰å‚æ•°
}
analyzer = Analyzer(config=custom_config)
```

### 3. å¤šçº§æ£€æµ‹

- **Level 1**: å£°å­¦ç‰¹å¾ï¼ˆå½“å‰å®ç°ï¼‰
- **Level 2**: MFCCéŸ³è‰²ç‰¹å¾ï¼ˆå¯é€‰ï¼‰
- **Level 3**: å¤§æ¨¡å‹æ¨ç†ï¼ˆæœªæ¥æ‰©å±•ï¼‰

---

## æŠ€æœ¯å€ºåŠ¡ä¸æ”¹è¿›æ–¹å‘

### å½“å‰é™åˆ¶

1. **è§„åˆ™æ­»æ¿**: é˜ˆå€¼å›ºå®šï¼Œéš¾ä»¥é€‚åº”æ‰€æœ‰åœºæ™¯
2. **è¯¯æŠ¥ç‡**: å¤æ‚åœºæ™¯ï¼ˆéŸ³ä¹ã€å¤šäººå¯¹è¯ï¼‰è¯¯æŠ¥è¾ƒé«˜
3. **æ— è¯­ä¹‰ç†è§£**: æ— æ³•åŒºåˆ†"æ•…æ„åœé¡¿"å’Œ"ç½‘ç»œå¡é¡¿"

### æ”¹è¿›æ–¹å‘

1. **é›†æˆLLM**ï¼ˆä¸‹ä¸€é˜¶æ®µï¼‰:
   - ä½¿ç”¨GPT-4o Audio APIè¿›è¡ŒäºŒæ¬¡éªŒè¯
   - ç”¨Whisperæå–è¯­ä¹‰embedding
   - å‡å°‘è¯¯æŠ¥ï¼Œæä¾›æ›´æ™ºèƒ½çš„åˆ†æ

2. **æœºå™¨å­¦ä¹ **:
   - è®­ç»ƒåˆ†ç±»å™¨ï¼ˆRandom Forest / XGBoostï¼‰
   - åŸºäºæ ‡æ³¨æ•°æ®é›†ä¼˜åŒ–é˜ˆå€¼
   - è‡ªé€‚åº”å­¦ä¹ ç”¨æˆ·åå¥½

3. **å¤šæ¨¡æ€åˆ†æ**:
   - ç»“åˆè§†é¢‘ï¼ˆå”‡å½¢åŒæ­¥æ£€æµ‹ï¼‰
   - ç»“åˆç½‘ç»œæŒ‡æ ‡ï¼ˆä¸¢åŒ…ç‡ã€å»¶è¿Ÿï¼‰

---

## æ€»ç»“

è¿™æ˜¯ä¸€ä¸ª**åŸºäºå£°å­¦ç‰¹å¾çš„è§„åˆ™å¼•æ“ç³»ç»Ÿ**ï¼Œæ ¸å¿ƒä¼˜åŠ¿æ˜¯ï¼š

âœ… **å¿«é€Ÿ**: æ— éœ€GPUï¼Œå®æ—¶å¤„ç†  
âœ… **å¯è§£é‡Š**: æ¯ä¸ªæ£€æµ‹éƒ½æœ‰æ˜ç¡®åŸå›   
âœ… **å¯é…ç½®**: çµæ´»çš„é˜ˆå€¼å’Œé¢„è®¾  
âœ… **å¯æ‰©å±•**: æ’ä»¶å¼æ¶æ„ï¼Œæ˜“äºæ·»åŠ æ–°æ£€æµ‹å™¨  

é€‚ç”¨åœºæ™¯ï¼š
- VoIPé€šè¯è´¨é‡ç›‘æ§
- éŸ³é¢‘å½•åˆ¶è´¨é‡æ£€æŸ¥
- å®æ—¶éŸ³é¢‘æµåˆ†æ

ä¸é€‚ç”¨åœºæ™¯ï¼š
- è¯­ä¹‰åˆ†æï¼ˆéœ€è¦LLMï¼‰
- éŸ³ä¹è´¨é‡è¯„ä¼°ï¼ˆéœ€è¦ä¸“ä¸šæŒ‡æ ‡ï¼‰
- æç«¯å¤æ‚åœºæ™¯ï¼ˆéœ€è¦æ·±åº¦å­¦ä¹ ï¼‰

---

**æ–‡æ¡£ç‰ˆæœ¬**: v1.0  
**æœ€åæ›´æ–°**: 2026å¹´1æœˆ27æ—¥  
**ç»´æŠ¤è€…**: Audio Quality Assessment Team
