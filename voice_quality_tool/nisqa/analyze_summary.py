"""
NISQAåŸºå‡†å¯¹æ¯”ç»“æœæ±‡æ€»åˆ†æå·¥å…·
è¯»å–æ‰€æœ‰baseline_compare_*.jsonæ–‡ä»¶ï¼Œç”Ÿæˆè´¨é‡é—®é¢˜æ±‡æ€»æŠ¥å‘Š
"""

import json
import os
from pathlib import Path
import numpy as np
from collections import defaultdict

def load_all_comparisons(output_dir):
    """åŠ è½½æ‰€æœ‰å¯¹æ¯”ç»“æœJSONæ–‡ä»¶"""
    comparisons = []
    json_files = sorted(Path(output_dir).glob('baseline_compare_*.json'))
    
    for json_file in json_files:
        try:
            with open(json_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
                comparisons.append({
                    'filename': json_file.stem.replace('baseline_compare_', ''),
                    'data': data
                })
        except Exception as e:
            print(f"[è­¦å‘Š] æ— æ³•è¯»å– {json_file}: {e}")
    
    return comparisons

def analyze_quality_issues(comparisons):
    """åˆ†æè´¨é‡é—®é¢˜"""
    
    # åˆ†ç±»ç»Ÿè®¡
    severe_issues = []  # ä¸¥é‡é—®é¢˜ï¼ˆ>50%å¸§ä½äºåŸºå‡†ï¼‰
    moderate_issues = []  # ä¸­ç­‰é—®é¢˜ï¼ˆ20-50%å¸§ä½äºåŸºå‡†ï¼‰
    good_quality = []  # è´¨é‡è‰¯å¥½ï¼ˆ<20%å¸§ä½äºåŸºå‡†ï¼‰
    
    # å„ç»´åº¦é—®é¢˜ç»Ÿè®¡
    dimension_stats = {
        'MOS': {'severe': [], 'moderate': [], 'good': []},
        'NOI': {'severe': [], 'moderate': [], 'good': []},
        'DIS': {'severe': [], 'moderate': [], 'good': []},
        'COL': {'severe': [], 'moderate': [], 'good': []},
        'LOUD': {'severe': [], 'moderate': [], 'good': []}
    }
    
    # æ–‡ä»¶çº§è´¨é‡è¯„åˆ†ï¼ˆåŸºäºMOSå·®å€¼ï¼‰
    mos_rankings = []
    
    for comp in comparisons:
        filename = comp['filename']
        data = comp['data']
        
        # è·å–metricsï¼ˆæ­£ç¡®çš„JSONç»“æ„ï¼‰
        metrics = data.get('metrics', {})
        
        # MOSç»´åº¦è¯„ä¼°
        mos_stats = metrics.get('mos', {}).get('stats', {})
        mos_below_pct = mos_stats.get('percent_below_baseline', 0)
        mos_mean_diff = mos_stats.get('mean_diff', 0)
        
        # æ–‡ä»¶çº§MOSå·®å€¼ï¼ˆä½¿ç”¨æ­£ç¡®çš„è·¯å¾„ï¼šfile_level.diff.mosï¼‰
        file_level = data.get('file_level', {})
        file_diff = file_level.get('diff', {})
        mos_file_diff = file_diff.get('mos', 0)
        
        mos_rankings.append({
            'filename': filename,
            'mos_diff': mos_file_diff,
            'mos_below_pct': mos_below_pct
        })
        
        # ç»Ÿè®¡å„ç»´åº¦é—®é¢˜ï¼ˆä½¿ç”¨æ­£ç¡®çš„ç»´åº¦åç§°æ˜ å°„ï¼‰
        dim_mapping = {
            'MOS': 'mos',
            'NOI': 'noi',
            'DIS': 'dis',
            'COL': 'col',
            'LOUD': 'loud'
        }
        
        for dim_upper, dim_lower in dim_mapping.items():
            dim_stats = metrics.get(dim_lower, {}).get('stats', {})
            below_pct = dim_stats.get('percent_below_baseline', 0)
            
            if below_pct > 50:
                dimension_stats[dim_upper]['severe'].append(filename)
            elif below_pct > 20:
                dimension_stats[dim_upper]['moderate'].append(filename)
            else:
                dimension_stats[dim_upper]['good'].append(filename)
        
        # åˆ¤æ–­æ•´ä½“è´¨é‡ï¼ˆåŸºäºMOSï¼‰
        if mos_below_pct > 50:
            severe_issues.append({
                'filename': filename,
                'mos_below_pct': mos_below_pct,
                'mos_file_diff': mos_file_diff,
                'metrics': metrics
            })
        elif mos_below_pct > 20:
            moderate_issues.append({
                'filename': filename,
                'mos_below_pct': mos_below_pct,
                'mos_file_diff': mos_file_diff
            })
        else:
            good_quality.append({
                'filename': filename,
                'mos_below_pct': mos_below_pct,
                'mos_file_diff': mos_file_diff
            })
    
    # æŒ‰MOSæ–‡ä»¶çº§å·®å€¼æ’åº
    mos_rankings.sort(key=lambda x: x['mos_diff'])
    
    return {
        'total': len(comparisons),
        'severe_issues': severe_issues,
        'moderate_issues': moderate_issues,
        'good_quality': good_quality,
        'dimension_stats': dimension_stats,
        'mos_rankings': mos_rankings
    }

def print_summary_report(analysis):
    """æ‰“å°æ±‡æ€»æŠ¥å‘Š"""
    print("=" * 100)
    print("NISQA åŸºå‡†å¯¹æ¯”åˆ†æ - è´¨é‡é—®é¢˜æ±‡æ€»æŠ¥å‘Š")
    print("=" * 100)
    
    total = analysis['total']
    severe = len(analysis['severe_issues'])
    moderate = len(analysis['moderate_issues'])
    good = len(analysis['good_quality'])
    
    print(f"\nğŸ“Š æ•´ä½“ç»Ÿè®¡ï¼ˆåŸºäºMOSæ€»ä½“è´¨é‡ï¼‰")
    print(f"  æ€»æ–‡ä»¶æ•°: {total}")
    print(f"  âœ“ è´¨é‡è‰¯å¥½: {good} ({good/total*100:.1f}%) - ä½äºåŸºå‡†å¸§æ•° <20%")
    print(f"  âš ï¸  ä¸­ç­‰åŠ£åŒ–: {moderate} ({moderate/total*100:.1f}%) - ä½äºåŸºå‡†å¸§æ•° 20-50%")
    print(f"  âœ— ä¸¥é‡åŠ£åŒ–: {severe} ({severe/total*100:.1f}%) - ä½äºåŸºå‡†å¸§æ•° >50%")
    
    # å„ç»´åº¦ç»Ÿè®¡
    print(f"\nğŸ“ˆ å„ç»´åº¦è´¨é‡åˆ†å¸ƒ")
    print(f"{'ç»´åº¦':<10} {'è´¨é‡è‰¯å¥½':<15} {'ä¸­ç­‰åŠ£åŒ–':<15} {'ä¸¥é‡åŠ£åŒ–':<15}")
    print("-" * 60)
    
    for dim_name in ['MOS', 'NOI', 'DIS', 'COL', 'LOUD']:
        stats = analysis['dimension_stats'][dim_name]
        good_count = len(stats['good'])
        mod_count = len(stats['moderate'])
        sev_count = len(stats['severe'])
        print(f"{dim_name:<10} {good_count:<15} {mod_count:<15} {sev_count:<15}")
    
    # æœ€å·®çš„20ä¸ªæ–‡ä»¶ï¼ˆMOSï¼‰
    print(f"\nâš ï¸  MOSè´¨é‡æœ€å·®çš„20ä¸ªæ–‡ä»¶")
    print(f"{'æ’å':<6} {'æ–‡ä»¶å':<60} {'MOSå·®å€¼':<12} {'ä½äºåŸºå‡†%':<12}")
    print("-" * 95)
    
    worst_20 = analysis['mos_rankings'][:20]
    for i, item in enumerate(worst_20, 1):
        print(f"{i:<6} {item['filename']:<60} {item['mos_diff']:>+8.3f}     {item['mos_below_pct']:>6.1f}%")
    
    # æœ€å¥½çš„10ä¸ªæ–‡ä»¶ï¼ˆMOSï¼‰
    print(f"\nâœ“ MOSè´¨é‡æœ€å¥½çš„10ä¸ªæ–‡ä»¶")
    print(f"{'æ’å':<6} {'æ–‡ä»¶å':<60} {'MOSå·®å€¼':<12} {'ä½äºåŸºå‡†%':<12}")
    print("-" * 95)
    
    best_10 = analysis['mos_rankings'][-10:][::-1]
    for i, item in enumerate(best_10, 1):
        print(f"{i:<6} {item['filename']:<60} {item['mos_diff']:>+8.3f}     {item['mos_below_pct']:>6.1f}%")
    
    # ä¸¥é‡é—®é¢˜è¯¦æƒ…
    if analysis['severe_issues']:
        print(f"\nğŸš¨ ä¸¥é‡è´¨é‡é—®é¢˜æ–‡ä»¶è¯¦æƒ…ï¼ˆMOSä½äºåŸºå‡†å¸§æ•°>50%ï¼‰")
        print("=" * 100)
        
        for item in sorted(analysis['severe_issues'], key=lambda x: x['mos_below_pct'], reverse=True):
            print(f"\nã€{item['filename']}ã€‘")
            print(f"  MOSä½äºåŸºå‡†å¸§æ•°: {item['mos_below_pct']:.1f}%")
            print(f"  æ–‡ä»¶çº§MOSå·®å€¼: {item['mos_file_diff']:+.3f}")
            
            # æ˜¾ç¤ºå„ç»´åº¦é—®é¢˜
            metrics = item['metrics']
            problem_dims = []
            dim_mapping = {'noi': 'NOI', 'dis': 'DIS', 'col': 'COL', 'loud': 'LOUD'}
            
            for dim_lower, dim_upper in dim_mapping.items():
                dim_stats = metrics.get(dim_lower, {}).get('stats', {})
                below_pct = dim_stats.get('percent_below_baseline', 0)
                if below_pct > 50:
                    problem_dims.append(f"{dim_upper}({below_pct:.1f}%)")
            
            if problem_dims:
                print(f"  å…¶ä»–é—®é¢˜ç»´åº¦: {', '.join(problem_dims)}")
    
    # NOIï¼ˆå™ªå£°ï¼‰é—®é¢˜çªå‡ºçš„æ–‡ä»¶
    noi_severe = analysis['dimension_stats']['NOI']['severe']
    if len(noi_severe) > 20:
        print(f"\nğŸ”Š NOIï¼ˆå™ªå£°ï¼‰é—®é¢˜ä¸¥é‡æ–‡ä»¶: {len(noi_severe)} ä¸ª")
        print("  å‰20ä¸ªå™ªå£°é—®é¢˜æœ€ä¸¥é‡çš„æ–‡ä»¶å·²åœ¨ä¸Šé¢MOSæœ€å·®åˆ—è¡¨ä¸­ä½“ç°")
    
    print("\n" + "=" * 100)
    print("åˆ†æå®Œæˆï¼")
    print(f"è¯¦ç»†æ•°æ®è¯·æŸ¥çœ‹: voice_quality_tool/nisqa/baseline_compare_*.json")
    print(f"å¯è§†åŒ–å›¾è¡¨:")
    print(f"  - ç»¼åˆå¯¹æ¯”å›¾: voice_quality_tool/nisqa/baseline_compare_all.png")
    print(f"  - è´¨é‡çƒ­åŠ›å›¾: voice_quality_tool/nisqa/baseline_compare_heatmap.png")
    print("=" * 100)

def save_summary_json(analysis, output_path):
    """ä¿å­˜æ±‡æ€»åˆ†æç»“æœä¸ºJSON"""
    summary = {
        'total_files': analysis['total'],
        'quality_distribution': {
            'good': len(analysis['good_quality']),
            'moderate': len(analysis['moderate_issues']),
            'severe': len(analysis['severe_issues'])
        },
        'dimension_statistics': {
            dim: {
                'good': len(stats['good']),
                'moderate': len(stats['moderate']),
                'severe': len(stats['severe'])
            }
            for dim, stats in analysis['dimension_stats'].items()
        },
        'worst_20_files': analysis['mos_rankings'][:20],
        'best_10_files': analysis['mos_rankings'][-10:][::-1],
        'severe_issue_files': [
            {
                'filename': item['filename'],
                'mos_below_pct': item['mos_below_pct'],
                'mos_file_diff': item['mos_file_diff']
            }
            for item in analysis['severe_issues']
        ]
    }
    
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(summary, f, ensure_ascii=False, indent=2)
    
    print(f"\n[å·²ä¿å­˜] æ±‡æ€»åˆ†æç»“æœ: {output_path}")

def main():
    import argparse
    
    parser = argparse.ArgumentParser(description='NISQAåŸºå‡†å¯¹æ¯”ç»“æœæ±‡æ€»åˆ†æ')
    parser.add_argument('--output-dir', default='.',
                       help='å¯¹æ¯”ç»“æœJSONæ–‡ä»¶æ‰€åœ¨ç›®å½•')
    parser.add_argument('--save-json', 
                       help='ä¿å­˜æ±‡æ€»ç»“æœä¸ºJSONæ–‡ä»¶ï¼ˆå¯é€‰ï¼‰')
    
    args = parser.parse_args()
    
    print("æ­£åœ¨åŠ è½½å¯¹æ¯”ç»“æœ...")
    comparisons = load_all_comparisons(args.output_dir)
    
    if not comparisons:
        print("[é”™è¯¯] æœªæ‰¾åˆ°ä»»ä½•baseline_compare_*.jsonæ–‡ä»¶")
        return
    
    print(f"å·²åŠ è½½ {len(comparisons)} ä¸ªå¯¹æ¯”ç»“æœ")
    
    print("\næ­£åœ¨åˆ†æè´¨é‡é—®é¢˜...")
    analysis = analyze_quality_issues(comparisons)
    
    print_summary_report(analysis)
    
    if args.save_json:
        save_summary_json(analysis, args.save_json)

if __name__ == '__main__':
    main()
