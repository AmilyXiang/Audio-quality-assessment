"""
NISQAåŸºå‡†å¯¹æ¯”ç»“æœæ±‡æ€»åˆ†æå·¥å…·
è¯»å–æ‰€æœ‰baseline_compare_*.jsonæ–‡ä»¶ï¼Œç”Ÿæˆè´¨é‡é—®é¢˜æ±‡æ€»æŠ¥å‘Š
"""

import json
import os
from pathlib import Path
import numpy as np
from collections import defaultdict

def load_all_comparisons(output_dir):
    """åŠ è½½æ‰€æœ‰å¯¹æ¯”ç»“æœJSONæ–‡ä»¶"""
    comparisons = []
    json_files = sorted(Path(output_dir).glob('baseline_compare_*.json'))
    
    for json_file in json_files:
        try:
            with open(json_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
                comparisons.append({
                    'filename': json_file.stem.replace('baseline_compare_', ''),
                    'data': data
                })
        except Exception as e:
            print(f"[è­¦å‘Š] æ— æ³•è¯»å– {json_file}: {e}")
    
    return comparisons

def analyze_quality_issues(comparisons):
    """åˆ†æè´¨é‡é—®é¢˜"""
    
    # OK/NOKåˆ†ç±»
    ok_files = []
    nok_files = []
    
    # é—®é¢˜ç»´åº¦ç»Ÿè®¡
    nok_by_dimension = defaultdict(list)
    
    for comp in comparisons:
        filename = comp['filename']
        data = comp['data']
        
        # è·å–çŠ¶æ€ï¼ˆæ–°çš„åˆ¤å®šå­—æ®µï¼‰
        status = data.get('status', 'UNKNOWN')
        nok_dimensions = data.get('nok_dimensions', [])
        nok_reasons = data.get('nok_reasons', {})
        
        # æ–‡ä»¶çº§å·®å€¼
        file_level = data.get('file_level', {})
        file_diff = file_level.get('diff', {})
        
        file_info = {
            'filename': filename,
            'status': status,
            'nok_dimensions': nok_dimensions,
            'nok_reasons': nok_reasons,
            'mos_diff': file_diff.get('mos', 0),
            'noi_diff': file_diff.get('noi', 0),
            'dis_diff': file_diff.get('dis', 0),
            'col_diff': file_diff.get('col', 0),
            'loud_diff': file_diff.get('loud', 0)
        }
        
        if status == 'OK':
            ok_files.append(file_info)
        else:  # NOK
            nok_files.append(file_info)
            # ç»Ÿè®¡å„é—®é¢˜ç»´åº¦
            for dim in nok_dimensions:
                nok_by_dimension[dim].append(filename)
    
    return {
        'total': len(comparisons),
        'ok_files': ok_files,
        'nok_files': nok_files,
        'nok_by_dimension': dict(nok_by_dimension)
    }

def print_summary_report(analysis):
    """æ‰“å°æ±‡æ€»æŠ¥å‘Š"""
    print("=" * 100)
    print("NISQA åŸºå‡†å¯¹æ¯”åˆ†æ - è´¨é‡é—®é¢˜æ±‡æ€»æŠ¥å‘Š")
    print("=" * 100)
    
    total = analysis['total']
    ok_count = len(analysis['ok_files'])
    nok_count = len(analysis['nok_files'])
    
    print(f"\nğŸ“Š æ•´ä½“ç»Ÿè®¡")
    print(f"  æ€»æ–‡ä»¶æ•°: {total}")
    print(f"  âœ“ OKæ–‡ä»¶: {ok_count} ({ok_count/total*100:.1f}%) - è´¨é‡ç›¸å½“æˆ–ä¼˜äºåŸºå‡†")
    print(f"  âœ— NOKæ–‡ä»¶: {nok_count} ({nok_count/total*100:.1f}%) - è´¨é‡åŠ£äºåŸºå‡†")
    
    # NOKç»´åº¦ç»Ÿè®¡
    if analysis['nok_by_dimension']:
        print(f"\nğŸ“ˆ NOKæ–‡ä»¶é—®é¢˜ç»´åº¦åˆ†å¸ƒ")
        print(f"{'ç»´åº¦':<15} {'æ–‡ä»¶æ•°':<10}")
        print("-" * 30)
        
        for dim, files in sorted(analysis['nok_by_dimension'].items()):
            print(f"{dim:<15} {len(files):<10}")
    
    # NOKæ–‡ä»¶è¯¦æƒ…
    if analysis['nok_files']:
        print(f"\nğŸš¨ NOKæ–‡ä»¶è¯¦æƒ…")
        print("=" * 100)
        
        for item in analysis['nok_files']:
            print(f"\nã€{item['filename']}ã€‘")
            print(f"  é—®é¢˜ç»´åº¦: {', '.join(item['nok_dimensions'])}")
            
            # æ˜¾ç¤ºåˆ¤å®šåŸå› 
            nok_reasons = item.get('nok_reasons', {})
            if nok_reasons:
                print(f"  åˆ¤å®šä¾æ®:")
                for dim, reason in nok_reasons.items():
                    print(f"    - {dim}: {reason}")
            
            print(f"  æ–‡ä»¶çº§å·®å€¼: MOS={item['mos_diff']:+.3f}, NOI={item['noi_diff']:+.3f}, "
                  f"DIS={item['dis_diff']:+.3f}, COL={item['col_diff']:+.3f}, LOUD={item['loud_diff']:+.3f}")
    
    print("\n" + "=" * 100)
    print("åˆ†æå®Œæˆï¼")
    print(f"è¯¦ç»†æ•°æ®è¯·æŸ¥çœ‹: voice_quality_tool/nisqa/baseline_compare_*.json")
    print(f"å¯è§†åŒ–å›¾è¡¨:")
    print(f"  - ç»¼åˆå¯¹æ¯”å›¾: voice_quality_tool/nisqa/baseline_compare_all.png")
    print(f"  - è´¨é‡çƒ­åŠ›å›¾: voice_quality_tool/nisqa/baseline_compare_heatmap.png")
    print("=" * 100)

def save_summary_json(analysis, output_path):
    """ä¿å­˜æ±‡æ€»åˆ†æç»“æœä¸ºJSON"""
    summary = {
        'total_files': analysis['total'],
        'quality_distribution': {
            'ok': len(analysis['ok_files']),
            'nok': len(analysis['nok_files'])
        },
        'nok_by_dimension': analysis['nok_by_dimension'],
        'ok_files': analysis['ok_files'],
        'nok_files': analysis['nok_files']
    }
    
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(summary, f, ensure_ascii=False, indent=2)
    
    print(f"\n[å·²ä¿å­˜] æ±‡æ€»åˆ†æç»“æœ: {output_path}")

def main():
    import argparse
    
    parser = argparse.ArgumentParser(description='NISQAåŸºå‡†å¯¹æ¯”ç»“æœæ±‡æ€»åˆ†æ')
    parser.add_argument('--output-dir', default='.',
                       help='å¯¹æ¯”ç»“æœJSONæ–‡ä»¶æ‰€åœ¨ç›®å½•')
    parser.add_argument('--save-json', 
                       help='ä¿å­˜æ±‡æ€»ç»“æœä¸ºJSONæ–‡ä»¶ï¼ˆå¯é€‰ï¼‰')
    
    args = parser.parse_args()
    
    print("æ­£åœ¨åŠ è½½å¯¹æ¯”ç»“æœ...")
    comparisons = load_all_comparisons(args.output_dir)
    
    if not comparisons:
        print("[é”™è¯¯] æœªæ‰¾åˆ°ä»»ä½•baseline_compare_*.jsonæ–‡ä»¶")
        return
    
    print(f"å·²åŠ è½½ {len(comparisons)} ä¸ªå¯¹æ¯”ç»“æœ")
    
    print("\næ­£åœ¨åˆ†æè´¨é‡é—®é¢˜...")
    analysis = analyze_quality_issues(comparisons)
    
    print_summary_report(analysis)
    
    if args.save_json:
        save_summary_json(analysis, args.save_json)

if __name__ == '__main__':
    main()
