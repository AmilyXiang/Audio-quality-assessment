#!/usr/bin/env python3
"""
å…¨å±€å¤±çœŸæ£€æµ‹ - æ£€æµ‹æ•´æ®µæ–‡ä»¶çš„ç³»ç»Ÿæ€§å¤±çœŸ

è§£å†³é—®é¢˜ï¼š
åŸå§‹ç³»ç»Ÿåªèƒ½æ£€æµ‹ç¦»æ•£äº‹ä»¶ï¼ˆçªå‘å¤±çœŸï¼‰
æ— æ³•æ£€æµ‹æ•´æ®µæ–‡ä»¶çš„æŒç»­ç³»ç»Ÿæ€§å¤±çœŸï¼ˆå¦‚æœºå™¨äººè¯­éŸ³ã€åˆæˆè¯­éŸ³ã€ç¼–ç å¤±çœŸç­‰ï¼‰

æ–¹æ¡ˆï¼šè®¡ç®—æ•´æ®µæ–‡ä»¶çš„å…¨å±€ç‰¹å¾ï¼Œä¸åŸºçº¿å¯¹æ¯”
"""

import numpy as np
from scipy.io import wavfile
from scipy import signal
import json
import os
from typing import Dict, Tuple
from .alignment import align_audio_precise


class GlobalDistortionAnalyzer:
    """å…¨å±€å¤±çœŸåˆ†æå™¨ - æ£€æµ‹æ•´æ®µæ–‡ä»¶çš„ç³»ç»Ÿæ€§å¤±çœŸ"""
    
    def __init__(self):
        self.name = "GlobalDistortionAnalyzer"
    
    def analyze_file(self, audio_path: str, baseline_audio_path: str = None) -> Dict:
        """
        åˆ†æå•ä¸ªæ–‡ä»¶ï¼Œå¯é€‰ä¸åŸºçº¿å¯¹æ¯”
        
        Args:
            audio_path: å¾…åˆ†æéŸ³é¢‘æ–‡ä»¶
            baseline_audio_path: åŸºçº¿éŸ³é¢‘æ–‡ä»¶ï¼ˆç”¨äºå¯¹æ¯”ï¼‰
        
        Returns:
            dict: åŒ…å«å…¨å±€ç‰¹å¾å’Œå¤±çœŸåˆ¤æ–­
        """
        
        print(f"\nğŸ“Š å…¨å±€å¤±çœŸåˆ†æ")
        print("=" * 70)
        
        # åŠ è½½éŸ³é¢‘
        sample_rate, data = wavfile.read(audio_path)
        if len(data.shape) > 1:
            data = data[:, 0]
        data = data.astype(float) / 32768.0
        
        print(f"ğŸ“ åˆ†ææ–‡ä»¶: {os.path.basename(audio_path)}")
        print(f"   é‡‡æ ·ç‡: {sample_rate} Hz")
        print(f"   æ—¶é•¿: {len(data) / sample_rate:.2f}s")
        print(f"   æ ·æœ¬æ•°: {len(data)}")
        
        # è®¡ç®—å…¨å±€ç‰¹å¾
        global_features = self._compute_global_features(data, sample_rate)
        
        result = {
            "file": os.path.basename(audio_path),
            "duration": len(data) / sample_rate,
            "sample_rate": sample_rate,
            "global_features": global_features,
            "quality_assessment": None,
            "baseline_comparison": None
        }
        
        # å¦‚æœæä¾›äº†åŸºçº¿ï¼Œè¿›è¡Œå¯¹æ¯”åˆ†æ
        if baseline_audio_path and os.path.exists(baseline_audio_path):
            sr_base, data_base = wavfile.read(baseline_audio_path)
            if len(data_base.shape) > 1:
                data_base = data_base[:, 0]
            data_base = data_base.astype(float) / 32768.0
            
            print(f"\nğŸ“‹ åŸºçº¿æ–‡ä»¶: {os.path.basename(baseline_audio_path)}")
            print(f"   é‡‡æ ·ç‡: {sr_base} Hz")
            print(f"   æ—¶é•¿: {len(data_base) / sr_base:.2f}s")
            
            # ğŸ”§ å¯¹é½éŸ³é¢‘ï¼šç»Ÿä¸€é‡‡æ ·ç‡ + äº’ç›¸å…³ç²—å¯¹é½ + DTWç²¾å¯¹é½ï¼ˆå¯é€‰ï¼‰
            print(f"\nğŸ”§ éŸ³é¢‘å¯¹é½å¤„ç†...")
            data, data_base, alignment_info = self._align_audio_v2(
                data, sample_rate, data_base, sr_base
            )
            print(f"   âœ“ å¯¹é½åé•¿åº¦: {len(data)} æ ·æœ¬ ({len(data)/sample_rate:.2f}s)")
            
            baseline_features = self._compute_global_features(data_base, sample_rate)
            comparison = self._compare_features(global_features, baseline_features)
            comparison['alignment_info'] = alignment_info
            
            result["baseline_comparison"] = comparison
            result["global_features"]["baseline"] = baseline_features
        
        # è´¨é‡è¯„ä¼°ï¼ˆä¼ å…¥åŸºçº¿å¯¹æ¯”ç»“æœï¼‰
        result["quality_assessment"] = self._assess_quality(
            global_features, 
            baseline_comparison=result.get("baseline_comparison")
        )
        
        self._print_results(result)
        
        return result
    
    def _align_audio_v2(self, data1: np.ndarray, sr1: int, data2: np.ndarray, sr2: int) -> Tuple[np.ndarray, np.ndarray, dict]:
        """
        å¯¹é½ä¸¤æ®µéŸ³é¢‘ï¼šç»Ÿä¸€é‡‡æ ·ç‡ + äº’ç›¸å…³ç²—å¯¹é½ + DTWç²¾å¯¹é½
        
        Args:
            data1: éŸ³é¢‘1æ•°æ®ï¼ˆæµ‹è¯•éŸ³é¢‘ï¼‰
            sr1: éŸ³é¢‘1é‡‡æ ·ç‡
            data2: éŸ³é¢‘2æ•°æ®ï¼ˆåŸºå‡†éŸ³é¢‘ï¼‰
            sr2: éŸ³é¢‘2é‡‡æ ·ç‡
            
        Returns:
            å¯¹é½åçš„ (data1, data2, alignment_info)
        """
        # 1. ç»Ÿä¸€é‡‡æ ·ç‡åˆ°è¾ƒé«˜çš„é‚£ä¸ª
        target_sr = max(sr1, sr2)
        
        if sr1 != target_sr:
            num_samples = int(len(data1) * target_sr / sr1)
            data1 = signal.resample(data1, num_samples)
            print(f"   é‡é‡‡æ ·æµ‹è¯•éŸ³é¢‘: {sr1}Hz -> {target_sr}Hz")
        
        if sr2 != target_sr:
            num_samples = int(len(data2) * target_sr / sr2)
            data2 = signal.resample(data2, num_samples)
            print(f"   é‡é‡‡æ ·åŸºå‡†éŸ³é¢‘: {sr2}Hz -> {target_sr}Hz")
        
        # 2. ç²¾ç¡®å¯¹é½ï¼ˆCross-Correlation + DTWï¼‰
        try:
            alignment_result = align_audio_precise(
                reference=data2,  # åŸºå‡†ä½œä¸ºå‚è€ƒ
                test=data1,       # æµ‹è¯•éŸ³é¢‘
                sr=target_sr,
                enable_coarse=True,
                enable_fine=False  # DTWå¯é€‰ï¼Œè®¡ç®—è¾ƒæ…¢
            )
            
            data1 = alignment_result['aligned_test']
            data2 = alignment_result['aligned_reference']
            
            alignment_info = {
                'method': alignment_result['alignment_quality'],
                'coarse_offset_sec': alignment_result['coarse_offset'] / target_sr,
                'coarse_confidence': alignment_result['coarse_confidence'],
                'fine_alignment': alignment_result.get('fine_alignment')
            }
            
        except Exception as e:
            print(f"   âš ï¸  å¯¹é½å¤±è´¥ï¼Œä½¿ç”¨ç®€å•è£å‰ª: {e}")
            # é™çº§åˆ°ç®€å•è£å‰ª
            min_len = min(len(data1), len(data2))
            data1 = data1[:min_len]
            data2 = data2[:min_len]
            alignment_info = {'method': 'simple_trim', 'error': str(e)}
        
        return data1, data2, alignment_info
    
    def _align_audio(self, data1: np.ndarray, sr1: int, data2: np.ndarray, sr2: int) -> Tuple[np.ndarray, np.ndarray]:
        """
        æ—§ç‰ˆå¯¹é½ï¼ˆå‘åå…¼å®¹ï¼‰ï¼šç»Ÿä¸€é‡‡æ ·ç‡ï¼Œè£å‰ªåˆ°ç›¸åŒé•¿åº¦
        """
        result = self._align_audio_v2(data1, sr1, data2, sr2)
        return result[0], result[1]  # åªè¿”å›éŸ³é¢‘ï¼Œä¸è¿”å›alignment_info
    
    def _compute_global_features(self, data: np.ndarray, sample_rate: int) -> Dict:
        """è®¡ç®—éŸ³é¢‘æ–‡ä»¶çš„å…¨å±€ç‰¹å¾"""
        
        features = {}
        
        # 1. èƒ½é‡ç‰¹å¾
        rms = np.sqrt(np.mean(data ** 2))
        features['rms_energy'] = float(rms)
        features['rms_db'] = float(20 * np.log10(rms + 1e-10))
        features['dynamic_range'] = float(np.max(np.abs(data)) - np.min(np.abs(data)))
        
        # 2. é¢‘è°±ç‰¹å¾
        fft = np.abs(np.fft.rfft(data))
        freqs = np.fft.rfftfreq(len(data), 1 / sample_rate)
        
        # é¢‘è°±ä¸­å¿ƒå’Œå¸¦å®½
        power = fft ** 2
        centroid = np.sum(freqs * power) / (np.sum(power) + 1e-10)
        bandwidth = np.sqrt(np.sum(((freqs - centroid) ** 2) * power) / (np.sum(power) + 1e-10))
        
        features['spectral_centroid_mean'] = float(centroid)
        features['spectral_bandwidth_mean'] = float(bandwidth)
        
        # é¢‘è°±èƒ½é‡åˆ†å¸ƒ
        low_freq_energy = np.sum(power[(freqs < 1000)])
        mid_freq_energy = np.sum(power[(freqs >= 1000) & (freqs < 4000)])
        high_freq_energy = np.sum(power[(freqs >= 4000)])
        total_energy = low_freq_energy + mid_freq_energy + high_freq_energy
        
        features['low_freq_ratio'] = float(low_freq_energy / (total_energy + 1e-10))      # 0-1kHz
        features['mid_freq_ratio'] = float(mid_freq_energy / (total_energy + 1e-10))      # 1-4kHz
        features['high_freq_ratio'] = float(high_freq_energy / (total_energy + 1e-10))    # >4kHz
        
        # 3. æ—¶åŸŸç‰¹å¾
        features['zcr_mean'] = float(np.mean(np.sum(np.abs(np.diff(np.sign(data))) / 2)) / len(data))
        
        # 4. æ•´ä½“ç¨³å®šæ€§
        # å°†ä¿¡å·åˆ†æˆ10ä¸ªæ®µï¼Œè®¡ç®—æ¯æ®µçš„ç»Ÿè®¡ç‰¹æ€§å˜åŒ–
        segment_length = len(data) // 10
        segment_rmss = []
        segment_centroids = []
        
        for i in range(10):
            segment = data[i * segment_length:(i + 1) * segment_length]
            if len(segment) > 0:
                seg_rms = np.sqrt(np.mean(segment ** 2))
                segment_rmss.append(seg_rms)
                
                seg_fft = np.abs(np.fft.rfft(segment))
                seg_freqs = np.fft.rfftfreq(len(segment), 1 / sample_rate)
                seg_power = seg_fft ** 2
                seg_centroid = np.sum(seg_freqs * seg_power) / (np.sum(seg_power) + 1e-10)
                segment_centroids.append(seg_centroid)
        
        # ç¨³å®šæ€§ = æ®µé—´å˜å¼‚ç³»æ•°
        features['rms_stability'] = float(np.std(segment_rmss) / (np.mean(segment_rmss) + 1e-10))
        features['centroid_stability'] = float(np.std(segment_centroids) / (np.mean(segment_centroids) + 1e-10))
        
        # 5. å¤±çœŸæŒ‡æ ‡
        # è°æ³¢å¤±çœŸï¼šæ£€æŸ¥ç‰¹å®šé¢‘ç‡æ¯”ä¾‹
        fundamental_range = (80, 300)  # äººå£°åŸºé¢‘èŒƒå›´
        fundamental_power = np.sum(power[(freqs >= fundamental_range[0]) & (freqs <= fundamental_range[1])])
        features['harmonic_clarity'] = float(fundamental_power / (np.sum(power) + 1e-10))
        
        # Crest Factor (å³°åº¦) - è¡¡é‡å†²å‡»ç‰¹æ€§
        # CF = Peak / RMS, æ­£å¸¸è¯­éŸ³ ~4-8, å¤±çœŸè¯­éŸ³ ~2-3
        crest_factor = (np.max(np.abs(data)) + 1e-10) / (rms + 1e-10)
        features['crest_factor'] = float(crest_factor)
        
        # å³°åº¦ï¼ˆKurtosisï¼‰- è¡¡é‡å°¾éƒ¨å°–é”åº¦
        # æ­£å¸¸è¯­éŸ³ ~3, å¤±çœŸ/åˆæˆ >5 æˆ– <2
        kurtosis = float(self._compute_kurtosis(data))
        features['kurtosis'] = kurtosis
        
        # 6. Melé¢‘è°±ç‰¹å¾ï¼ˆäººè€³æ„ŸçŸ¥ï¼‰
        mel_spec = self._compute_mel_spectrogram(data, sample_rate)
        features['mel_entropy'] = float(self._compute_entropy(mel_spec))
        features['mel_flatness'] = float(self._compute_spectral_flatness(mel_spec))
        
        return features
    
    def _compute_kurtosis(self, data: np.ndarray) -> float:
        """è®¡ç®—å³°åº¦ï¼ˆKurtosisï¼‰"""
        mean = np.mean(data)
        std = np.std(data)
        if std == 0:
            return 0
        return np.mean(((data - mean) / std) ** 4)
    
    def _compute_mel_spectrogram(self, data: np.ndarray, sample_rate: int, n_mels: int = 13) -> np.ndarray:
        """è®¡ç®—Melé¢‘è°±ï¼ˆç®€åŒ–ç‰ˆï¼‰"""
        
        # ä½¿ç”¨Melæ»¤æ³¢å™¨è¿‘ä¼¼
        n_fft = 2048
        hop_length = 512
        
        # ç®€å•çš„æ—¶é¢‘åˆ†æ
        num_frames = (len(data) - n_fft) // hop_length + 1
        mel_spec = np.zeros((num_frames, n_mels))
        
        for i in range(num_frames):
            frame = data[i * hop_length:i * hop_length + n_fft]
            if len(frame) < n_fft:
                frame = np.pad(frame, (0, n_fft - len(frame)))
            
            # è®¡ç®—åŠŸç‡è°±
            fft = np.abs(np.fft.rfft(frame))
            power = fft ** 2
            
            # ç®€åŒ–ï¼šå°†åŠŸç‡è°±åˆ†æˆn_melsä¸ªæ¢…å°”é¢‘ç‡æ®µ
            for j in range(n_mels):
                freq_start = int(j * len(power) / n_mels)
                freq_end = int((j + 1) * len(power) / n_mels)
                mel_spec[i, j] = np.mean(power[freq_start:freq_end])
        
        # å¯¹æ•´ä¸ªé¢‘è°±æ±‚å¹³å‡
        return np.mean(mel_spec, axis=0)
    
    def _compute_entropy(self, spectrum: np.ndarray) -> float:
        """è®¡ç®—é¢‘è°±ç†µï¼ˆè¡¡é‡åˆ†æ•£åº¦ï¼‰"""
        spectrum = np.abs(spectrum)
        spectrum = spectrum / (np.sum(spectrum) + 1e-10)
        entropy = -np.sum(spectrum * np.log(spectrum + 1e-10))
        return entropy
    
    def _compute_spectral_flatness(self, spectrum: np.ndarray) -> float:
        """è®¡ç®—é¢‘è°±å¹³å¦åº¦ï¼ˆWiener Entropyï¼‰"""
        spectrum = np.abs(spectrum) + 1e-10
        geometric_mean = np.exp(np.mean(np.log(spectrum)))
        arithmetic_mean = np.mean(spectrum)
        flatness = geometric_mean / (arithmetic_mean + 1e-10)
        return flatness
    
    def _compare_features(self, test_features: Dict, baseline_features: Dict) -> Dict:
        """æ¯”è¾ƒæµ‹è¯•ç‰¹å¾ä¸åŸºçº¿ç‰¹å¾"""
        
        comparison = {
            "differences": {},
            "anomaly_scores": {},
            "overall_distortion_index": 0.0
        }
        
        # å…³é”®ç‰¹å¾å¯¹æ¯”
        key_features = [
            'rms_energy',
            'spectral_centroid_mean',
            'spectral_bandwidth_mean',
            'low_freq_ratio',
            'mid_freq_ratio',
            'high_freq_ratio',
            'rms_stability',
            'centroid_stability',
            'harmonic_clarity',
            'crest_factor',
            'kurtosis',
            'mel_entropy',
            'mel_flatness'
        ]
        
        anomaly_scores = []
        
        for feature in key_features:
            test_val = test_features.get(feature, 0)
            baseline_val = baseline_features.get(feature, 0)
            
            if baseline_val == 0:
                diff_ratio = 0
            else:
                diff_ratio = (test_val - baseline_val) / (abs(baseline_val) + 1e-10)
            
            comparison["differences"][feature] = {
                "test": test_val,
                "baseline": baseline_val,
                "diff_ratio": diff_ratio
            }
            
            # å¼‚å¸¸åº¦è¯„åˆ†ï¼ˆåŸºäºåç¦»ç¨‹åº¦ï¼‰
            anomaly = self._calculate_anomaly_score(feature, diff_ratio, test_val, baseline_val)
            comparison["anomaly_scores"][feature] = anomaly
            anomaly_scores.append(anomaly)
        
        # ç»¼åˆå¼‚å¸¸æŒ‡æ•°
        comparison["overall_distortion_index"] = float(np.mean(anomaly_scores))
        
        return comparison
    
    def _calculate_anomaly_score(self, feature_name: str, diff_ratio: float, test_val: float, baseline_val: float) -> float:
        """
        è®¡ç®—ç‰¹å®šç‰¹å¾çš„å¼‚å¸¸åº¦ [0, 1]
        """
        
        # ä¸åŒç‰¹å¾æœ‰ä¸åŒçš„æ­£å¸¸åå·®èŒƒå›´
        expected_ranges = {
            'rms_energy': 0.3,          # Â±30% æ­£å¸¸
            'spectral_centroid_mean': 0.2,
            'spectral_bandwidth_mean': 0.25,
            'low_freq_ratio': 0.15,
            'mid_freq_ratio': 0.15,
            'high_freq_ratio': 0.20,
            'rms_stability': 0.5,       # ç¨³å®šæ€§å·®å¼‚è¾ƒå¤§
            'centroid_stability': 0.4,
            'harmonic_clarity': 0.2,
            'crest_factor': 0.3,        # Â±30%
            'kurtosis': 1.0,            # å³°åº¦å·®å¼‚å¤§
            'mel_entropy': 0.2,
            'mel_flatness': 0.3
        }
        
        expected_range = expected_ranges.get(feature_name, 0.2)
        
        # å¼‚å¸¸åº¦ = max(0, (å®é™…åå·® - é¢„æœŸåå·®) / é¢„æœŸåå·®)
        if abs(diff_ratio) <= expected_range:
            return 0.0
        else:
            anomaly = min(1.0, (abs(diff_ratio) - expected_range) / expected_range)
            return anomaly
    
    def _assess_quality(self, features: Dict, baseline_comparison: Dict = None) -> Dict:
        """å¯¹æ•´æ®µæ–‡ä»¶è¿›è¡Œè´¨é‡è¯„ä¼°
        
        Args:
            features: æµ‹è¯•éŸ³é¢‘çš„å…¨å±€ç‰¹å¾
            baseline_comparison: åŸºçº¿å¯¹æ¯”ç»“æœï¼ˆå¯é€‰ï¼‰
            
        Returns:
            åŒ…å«è´¨é‡è¯„ä¼°çš„å­—å…¸
        """
        
        # å¦‚æœæœ‰åŸºçº¿å¯¹æ¯”ï¼Œä¼˜å…ˆä½¿ç”¨ç›¸å¯¹è¯„ä¼°
        if baseline_comparison:
            return self._assess_quality_relative(features, baseline_comparison)
        
        # å¦åˆ™ä½¿ç”¨ç»å¯¹è¯„ä¼°ï¼ˆåŸºäºç†è®ºæ ‡å‡†ï¼‰
        assessment = {
            "overall_quality": "GOOD",
            "quality_score": 1.0,  # 0-1, 1=æœ€å¥½
            "issues": [],
            "details": {},
            "evaluation_method": "absolute"
        }
        
        score = 1.0
        
        # 1. æ£€æŸ¥Crest Factorï¼ˆå³°åº¦å¼‚å¸¸ = å¤±çœŸè¿¹è±¡ï¼‰
        cf = features.get('crest_factor', 5.0)
        if cf < 2.5 or cf > 8.0:  # åç¦»æ­£å¸¸èŒƒå›´
            assessment["issues"].append(f"å¼‚å¸¸Crest Factor: {cf:.2f} (é¢„æœŸ: 4-8)")
            score -= 0.15
            assessment["details"]["crest_factor_issue"] = "å¯èƒ½å­˜åœ¨ä¸¥é‡å¤±çœŸæˆ–åˆæˆè¯­éŸ³"
        
        # 2. æ£€æŸ¥å³°åº¦ï¼ˆKurtosisï¼‰
        kurtosis = features.get('kurtosis', 3.0)
        if kurtosis > 5.0 or kurtosis < 1.5:  # åç¦»æ­£å¸¸èŒƒå›´
            assessment["issues"].append(f"å¼‚å¸¸å³°åº¦: {kurtosis:.2f} (é¢„æœŸ: 2-4)")
            score -= 0.15
            assessment["details"]["kurtosis_issue"] = "é¢‘è°±åˆ†å¸ƒå¼‚å¸¸ï¼Œå¯èƒ½æ˜¯åˆæˆæˆ–ç¼–ç å¤±çœŸ"
        
        # 3. æ£€æŸ¥è°æ³¢æ¸…æ™°åº¦
        harmonic_clarity = features.get('harmonic_clarity', 0.3)
        if harmonic_clarity < 0.15:
            assessment["issues"].append(f"è°æ³¢æ¸…æ™°åº¦ä½: {harmonic_clarity:.3f}")
            score -= 0.15
            assessment["details"]["low_harmonic_clarity"] = "å¯èƒ½æ˜¯å¹¿å¸¦å™ªå£°æˆ–å¤±çœŸ"
        
        # 4. æ£€æŸ¥é¢‘è°±å¹³å¦åº¦
        mel_flatness = features.get('mel_flatness', 0.5)
        if mel_flatness < 0.3:
            assessment["issues"].append(f"Melé¢‘è°±å¹³å¦åº¦ä½: {mel_flatness:.3f}")
            score -= 0.1
            assessment["details"]["low_spectral_flatness"] = "é¢‘è°±è¿‡äºå°–é”ï¼Œå¯èƒ½å­˜åœ¨ç¼–ç å¤±çœŸ"
        
        # 5. æ£€æŸ¥ç¨³å®šæ€§
        rms_stability = features.get('rms_stability', 0.2)
        if rms_stability > 0.5:
            assessment["issues"].append(f"RMSç¨³å®šæ€§å·®: {rms_stability:.3f}")
            score -= 0.1
            assessment["details"]["poor_rms_stability"] = "éŸ³é‡æ³¢åŠ¨å¼‚å¸¸"
        
        centroid_stability = features.get('centroid_stability', 0.15)
        if centroid_stability > 0.4:
            assessment["issues"].append(f"ä¸­å¿ƒé¢‘ç‡ç¨³å®šæ€§å·®: {centroid_stability:.3f}")
            score -= 0.1
            assessment["details"]["poor_centroid_stability"] = "é¢‘è°±ç‰¹æ€§æ³¢åŠ¨å¼‚å¸¸"
        
        # 6. é¢‘ç‡åˆ†å¸ƒæ£€æŸ¥
        low_freq = features.get('low_freq_ratio', 0.2)
        high_freq = features.get('high_freq_ratio', 0.2)
        
        if low_freq > 0.6 or high_freq > 0.5:
            assessment["issues"].append(f"é¢‘è°±åˆ†å¸ƒå¼‚å¸¸: ä½é¢‘{low_freq:.1%}, é«˜é¢‘{high_freq:.1%}")
            score -= 0.1
            assessment["details"]["abnormal_freq_distribution"] = "å¯èƒ½æ˜¯ç¼–ç å¤±çœŸæˆ–ç‰¹æ®Šå¤„ç†"
        
        score = max(0.0, score)
        assessment["quality_score"] = score
        
        # åˆ¤æ–­è´¨é‡ç­‰çº§
        if score >= 0.85:
            assessment["overall_quality"] = "âœ… GOOD (æ­£å¸¸)"
        elif score >= 0.70:
            assessment["overall_quality"] = "âš ï¸  FAIR (è½»å¾®é—®é¢˜)"
        elif score >= 0.50:
            assessment["overall_quality"] = "âŒ POOR (æ˜¾è‘—é—®é¢˜)"
        else:
            assessment["overall_quality"] = "ğŸš« DISTORTED (ä¸¥é‡å¤±çœŸ)"
        
        return assessment
    
    def _assess_quality_relative(self, features: Dict, baseline_comparison: Dict) -> Dict:
        """åŸºäºåŸºçº¿çš„ç›¸å¯¹è´¨é‡è¯„ä¼°
        
        Args:
            features: æµ‹è¯•éŸ³é¢‘çš„å…¨å±€ç‰¹å¾
            baseline_comparison: åŸºçº¿å¯¹æ¯”ç»“æœ
            
        Returns:
            ç›¸å¯¹è´¨é‡è¯„ä¼°ç»“æœ
        """
        distortion_index = baseline_comparison.get("overall_distortion_index", 0)
        anomaly_scores = baseline_comparison.get("anomaly_scores", {})
        differences = baseline_comparison.get("differences", {})
        
        # åŸºäºå¤±çœŸæŒ‡æ•°è®¡ç®—åˆ†æ•°
        score = max(0.0, 1.0 - distortion_index)
        
        # æ ¹æ®å¤±çœŸåº¦åˆ†çº§
        if distortion_index < 0.15:
            quality_label = "âœ… EXCELLENT (ä¸åŸºçº¿é«˜åº¦ä¸€è‡´)"
        elif distortion_index < 0.30:
            quality_label = "âœ… GOOD (ä¸åŸºçº¿æ¥è¿‘)"
        elif distortion_index < 0.50:
            quality_label = "âš ï¸  FAIR (ä¸åŸºçº¿æœ‰å·®å¼‚)"
        else:
            quality_label = "âŒ POOR (ä¸åŸºçº¿å·®å¼‚æ˜¾è‘—)"
        
        assessment = {
            "overall_quality": quality_label,
            "quality_score": score,
            "evaluation_method": "relative",
            "baseline_distortion_index": distortion_index,
            "issues": [],
            "details": {}
        }
        
        # åˆ—å‡ºä¸»è¦å¼‚å¸¸é¡¹ï¼ˆå¼‚å¸¸åº¦ >= 0.8ï¼‰
        high_anomaly_features = []
        for feature, anomaly in anomaly_scores.items():
            if anomaly >= 0.8:
                diff_info = differences.get(feature, {})
                test_val = diff_info.get('test', 0)
                baseline_val = diff_info.get('baseline', 0)
                diff_ratio = diff_info.get('diff_ratio', 0)
                
                # æ ¼å¼åŒ–ç‰¹å¾å
                feature_name = feature.replace('_', ' ').title()
                
                if abs(diff_ratio) > 0.01:
                    assessment["issues"].append(
                        f"{feature_name}: {test_val:.4g} (åŸºçº¿: {baseline_val:.4g}, åå·®: {diff_ratio:+.1%})"
                    )
                    high_anomaly_features.append(feature_name)
        
        # æ·»åŠ è¯¦ç»†è¯´æ˜
        if distortion_index < 0.15:
            assessment["details"]["summary"] = "æµ‹è¯•éŸ³é¢‘ä¸åŸºçº¿é«˜åº¦ä¸€è‡´ï¼Œè´¨é‡ç¨³å®š"
        elif distortion_index < 0.30:
            assessment["details"]["summary"] = "æµ‹è¯•éŸ³é¢‘ä¸åŸºçº¿æ¥è¿‘ï¼Œæœ‰è½»å¾®å·®å¼‚"
        elif distortion_index < 0.50:
            assessment["details"]["summary"] = f"æµ‹è¯•éŸ³é¢‘ä¸åŸºçº¿å­˜åœ¨æ˜æ˜¾å·®å¼‚ï¼Œä¸»è¦é—®é¢˜ï¼š{', '.join(high_anomaly_features[:3]) if high_anomaly_features else 'å¤šé¡¹æŒ‡æ ‡åç¦»'}"
        else:
            assessment["details"]["summary"] = f"æµ‹è¯•éŸ³é¢‘ä¸åŸºçº¿å·®å¼‚æ˜¾è‘—ï¼Œéœ€è¦æ”¹å–„ï¼š{', '.join(high_anomaly_features[:3]) if high_anomaly_features else 'å¤šé¡¹æŒ‡æ ‡ä¸¥é‡åç¦»'}"
        
        return assessment
    
    def _print_results(self, result: Dict):
        """æ‰“å°åˆ†æç»“æœ"""
        
        print("\n" + "=" * 70)
        print("ğŸ“ˆ å…¨å±€ç‰¹å¾")
        print("=" * 70)
        
        features = result["global_features"]
        
        print(f"\nèƒ½é‡ç‰¹å¾:")
        print(f"  RMS Energy: {features.get('rms_energy', 0):.6f} ({features.get('rms_db', 0):.2f} dB)")
        print(f"  Dynamic Range: {features.get('dynamic_range', 0):.6f}")
        
        print(f"\né¢‘è°±ç‰¹å¾:")
        print(f"  Spectral Centroid: {features.get('spectral_centroid_mean', 0):.2f} Hz")
        print(f"  Spectral Bandwidth: {features.get('spectral_bandwidth_mean', 0):.2f} Hz")
        print(f"  Low Freq (<1kHz): {features.get('low_freq_ratio', 0):.1%}")
        print(f"  Mid Freq (1-4kHz): {features.get('mid_freq_ratio', 0):.1%}")
        print(f"  High Freq (>4kHz): {features.get('high_freq_ratio', 0):.1%}")
        
        print(f"\nç¨³å®šæ€§æŒ‡æ ‡:")
        print(f"  RMS Stability: {features.get('rms_stability', 0):.4f} (ä½=ç¨³å®š)")
        print(f"  Centroid Stability: {features.get('centroid_stability', 0):.4f}")
        
        print(f"\nå¤±çœŸæŒ‡æ ‡:")
        print(f"  Crest Factor: {features.get('crest_factor', 0):.2f} (æ­£å¸¸: 4-8)")
        print(f"  Kurtosis: {features.get('kurtosis', 0):.2f} (æ­£å¸¸: 2-4)")
        print(f"  Harmonic Clarity: {features.get('harmonic_clarity', 0):.3f}")
        print(f"  Mel Entropy: {features.get('mel_entropy', 0):.3f}")
        print(f"  Mel Flatness: {features.get('mel_flatness', 0):.3f}")
        
        # è´¨é‡è¯„ä¼°
        qa = result["quality_assessment"]
        eval_method = qa.get("evaluation_method", "unknown")
        
        print("\n" + "=" * 70)
        print("ğŸ¯ è´¨é‡è¯„ä¼°")
        print("=" * 70)
        
        # æ˜¾ç¤ºè¯„ä¼°æ–¹æ³•
        if eval_method == "relative":
            print("\nğŸ“Š è¯„ä¼°æ¨¡å¼: ç›¸å¯¹è¯„ä¼°ï¼ˆåŸºäºåŸºçº¿å¯¹æ¯”ï¼‰")
            distortion_idx = qa.get("baseline_distortion_index", 0)
            print(f"ä¸åŸºçº¿å·®å¼‚æŒ‡æ•°: {distortion_idx:.2%}")
        else:
            print("\nğŸ“Š è¯„ä¼°æ¨¡å¼: ç»å¯¹è¯„ä¼°ï¼ˆåŸºäºç†è®ºæ ‡å‡†ï¼‰")
        
        print(f"\næ•´ä½“è´¨é‡: {qa['overall_quality']}")
        print(f"è´¨é‡åˆ†æ•°: {qa['quality_score']:.2f} / 1.00")
        
        # æ˜¾ç¤ºæ‘˜è¦
        summary = qa.get("details", {}).get("summary")
        if summary:
            print(f"\n{summary}")
        
        if qa["issues"]:
            print(f"\n{'ä¸»è¦å·®å¼‚é¡¹' if eval_method == 'relative' else 'æ£€æµ‹åˆ°çš„é—®é¢˜'} ({len(qa['issues'])} é¡¹):")
            for issue in qa["issues"]:
                print(f"  âš ï¸  {issue}")
        else:
            if eval_method == "relative":
                print("\nâœ… å„é¡¹æŒ‡æ ‡ä¸åŸºçº¿ä¸€è‡´")
            else:
                print("\nâœ“ æœªæ£€æµ‹åˆ°æ˜æ˜¾é—®é¢˜")
        
        # åŸºçº¿å¯¹æ¯”
        if result["baseline_comparison"]:
            comp = result["baseline_comparison"]
            print("\n" + "=" * 70)
            print("ğŸ“Š ä¸åŸºçº¿å¯¹æ¯”")
            print("=" * 70)
            print(f"\næ•´ä½“å¤±çœŸæŒ‡æ•°: {comp['overall_distortion_index']:.2%}")
            
            if comp['overall_distortion_index'] > 0.15:
                print(f"âš ï¸  æ£€æµ‹åˆ°æ˜¾è‘—å¤±çœŸ (åå·® > 15%)")
                print(f"\nä¸»è¦å·®å¼‚ç‰¹å¾:")
                
                # æ˜¾ç¤ºå¼‚å¸¸åº¦æœ€é«˜çš„ç‰¹å¾
                top_anomalies = sorted(
                    comp['anomaly_scores'].items(),
                    key=lambda x: x[1],
                    reverse=True
                )[:5]
                
                for feature, anomaly_score in top_anomalies:
                    if anomaly_score > 0:
                        diff_info = comp['differences'][feature]
                        print(f"  {feature}:")
                        print(f"    å¼‚å¸¸åº¦: {anomaly_score:.1%}")
                        print(f"    æµ‹è¯•å€¼: {diff_info['test']:.4f}")
                        print(f"    åŸºçº¿å€¼: {diff_info['baseline']:.4f}")
                        print(f"    åç¦»: {diff_info['diff_ratio']:+.1%}")
            else:
                print(f"âœ“ ä¸åŸºçº¿å·®å¼‚åœ¨æ­£å¸¸èŒƒå›´å†…")


def main():
    """å‘½ä»¤è¡Œå…¥å£"""
    import sys
    
    if len(sys.argv) < 2:
        print("ç”¨æ³•: python global_distortion_analyzer.py <audio_file> [baseline_file]")
        print("\nç¤ºä¾‹:")
        print("  python global_distortion_analyzer.py test.wav")
        print("  python global_distortion_analyzer.py test.wav baseline.wav")
        return
    
    audio_file = sys.argv[1]
    baseline_file = sys.argv[2] if len(sys.argv) > 2 else None
    
    if not os.path.exists(audio_file):
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {audio_file}")
        return
    
    analyzer = GlobalDistortionAnalyzer()
    result = analyzer.analyze_file(audio_file, baseline_file)


if __name__ == '__main__':
    main()
