#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¹²å‡€è¯­éŸ³åˆ†æç¤ºä¾‹

å±•ç¤ºå¦‚ä½•ä½¿ç”¨è¶…å®½æ¾é…ç½®åˆ†æé«˜è´¨é‡å½•éŸ³å®¤å½•éŸ³ã€æ’­å®¢ç­‰å¹²å‡€è¯­éŸ³ã€‚
è¿™ç§é…ç½®å¯ä»¥æ˜¾è‘—å‡å°‘è¯¯æŠ¥ï¼Œé€‚åˆä¸“ä¸šéŸ³é¢‘ç¯å¢ƒã€‚
"""

import sys
import os

# æ·»åŠ çˆ¶ç›®å½•åˆ°è·¯å¾„
parent_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.insert(0, parent_dir)

# åˆ‡æ¢å·¥ä½œç›®å½•åˆ°é¡¹ç›®æ ¹ç›®å½•
os.chdir(parent_dir)

from analyzer.config import Config
from analyzer.audio_loader import load_audio_file
from analyzer.detector_pipeline import DetectorPipeline
from analyzer.result import AnalysisResult


def analyze_clean_speech(audio_path: str):
    """
    ä½¿ç”¨å¹²å‡€è¯­éŸ³é…ç½®åˆ†æéŸ³é¢‘æ–‡ä»¶
    
    Args:
        audio_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
    """
    print(f"ğŸ™ï¸  åˆ†ææ–‡ä»¶: {audio_path}")
    print(f"{'=' * 70}\n")
    
    # ============================================================
    # 1. åˆ›å»ºå¹²å‡€è¯­éŸ³é…ç½®
    # ============================================================
    clean_config = Config(
        # æœ€å°æŒç»­æ—¶é—´ï¼šæ¯”é»˜è®¤å€¼æé«˜ 3-4 å€
        min_dropout_duration=0.20,      # é»˜è®¤: 0.05s
        min_distortion_duration=0.50,   # é»˜è®¤: 0.12s
        min_noise_duration=0.60,        # é»˜è®¤: 0.15s
        min_volume_duration=1.00,       # é»˜è®¤: 0.25s
        
        # é˜ˆå€¼å€æ•°
        dropout_threshold_multiplier=3.0,
        volume_threshold_multiplier=2.0,
        
        # VADè®¾ç½®
        vad_enabled=True,
        vad_frame_duration_ms=20,
        vad_padding_duration_ms=200,
        vad_energy_threshold=0.02,
        
        # é‡‡æ ·ç‡å°†ä»éŸ³é¢‘æ–‡ä»¶è‡ªåŠ¨æ£€æµ‹
        sample_rate=None
    )
    
    print("ğŸ“‹ é…ç½®è¯¦æƒ…:")
    print(f"  æœ€å°å¡é¡¿æ—¶é•¿: {clean_config.min_dropout_duration}s")
    print(f"  æœ€å°å¤±çœŸæ—¶é•¿: {clean_config.min_distortion_duration}s")
    print(f"  æœ€å°å™ªå£°æ—¶é•¿: {clean_config.min_noise_duration}s")
    print(f"  æœ€å°éŸ³é‡æ³¢åŠ¨æ—¶é•¿: {clean_config.min_volume_duration}s")
    print(f"  VADå¯ç”¨: {clean_config.vad_enabled}")
    print()
    
    # ============================================================
    # 2. åŠ è½½éŸ³é¢‘æ–‡ä»¶
    # ============================================================
    print("ğŸ“‚ åŠ è½½éŸ³é¢‘æ–‡ä»¶...")
    try:
        frames, sample_rate, duration = load_audio_file(audio_path)
        print(f"  âœ… åŠ è½½æˆåŠŸ")
        print(f"  é‡‡æ ·ç‡: {sample_rate} Hz")
        print(f"  æ—¶é•¿: {duration:.2f} ç§’")
        print(f"  æ€»å¸§æ•°: {len(frames)}")
        print()
    except Exception as e:
        print(f"  âŒ åŠ è½½å¤±è´¥: {e}")
        return
    
    # æ›´æ–°é…ç½®ä¸­çš„é‡‡æ ·ç‡
    clean_config.sample_rate = sample_rate
    
    # ============================================================
    # 3. è¿è¡Œæ£€æµ‹
    # ============================================================
    print("ğŸ” å¼€å§‹åˆ†æ...")
    pipeline = DetectorPipeline(clean_config)
    result = AnalysisResult()
    
    for event in pipeline.process(frames):
        result.add_event(event)
    
    result.finalize(duration)
    print("  âœ… åˆ†æå®Œæˆ\n")
    
    # ============================================================
    # 4. æ˜¾ç¤ºç»“æœ
    # ============================================================
    print(f"{'=' * 70}")
    print(f"ğŸ“Š æ£€æµ‹ç»“æœ")
    print(f"{'=' * 70}\n")
    
    data = result.to_dict()
    
    print(f"å™ªå£° (NOISE):           {data['noise']['count']} ä¸ª")
    print(f"å¡é¡¿ (DROPOUT):         {data['dropout']['count']} ä¸ª")
    print(f"éŸ³é‡æ³¢åŠ¨ (VOLUME):       {data['volume_fluctuation']['count']} ä¸ª")
    print(f"å¤±çœŸ (DISTORTION):      {data['voice_distortion']['count']} ä¸ª")
    print(f"{'-' * 70}")
    
    total = (data['noise']['count'] + 
             data['dropout']['count'] + 
             data['volume_fluctuation']['count'] + 
             data['voice_distortion']['count'])
    print(f"æ€»è®¡:                   {total} ä¸ª\n")
    
    # ============================================================
    # 5. è´¨é‡è¯„ä¼°
    # ============================================================
    if total == 0:
        quality = "ä¼˜ç§€"
        emoji = "ğŸ‰"
    elif total <= 5:
        quality = "è‰¯å¥½"
        emoji = "âœ…"
    elif total <= 15:
        quality = "ä¸€èˆ¬"
        emoji = "âš ï¸"
    else:
        quality = "è¾ƒå·®"
        emoji = "âŒ"
    
    print(f"{emoji} éŸ³é¢‘è´¨é‡: {quality}")
    print()
    
    # ============================================================
    # 6. è¯¦ç»†äº‹ä»¶åˆ—è¡¨
    # ============================================================
    if total > 0:
        print(f"{'=' * 70}")
        print(f"ğŸ“ äº‹ä»¶è¯¦æƒ…")
        print(f"{'=' * 70}\n")
        
        # æŒ‰ç±»å‹åˆ†ç»„æ˜¾ç¤º
        for event_type in ['noise', 'dropout', 'volume_fluctuation', 'voice_distortion']:
            type_data = data[event_type]
            if type_data['count'] > 0:
                type_names = {
                    'noise': 'å™ªå£°',
                    'dropout': 'å¡é¡¿',
                    'volume_fluctuation': 'éŸ³é‡æ³¢åŠ¨',
                    'voice_distortion': 'å¤±çœŸ'
                }
                print(f"\nã€{type_names[event_type]}ã€‘å…± {type_data['count']} ä¸ª:")
                
                for i, event in enumerate(type_data['events'], 1):
                    print(f"  {i}. {event['start_time']:.2f}s - {event['end_time']:.2f}s "
                          f"(æŒç»­ {event['duration']:.3f}s)")
                    if 'metadata' in event and event['metadata']:
                        for key, value in event['metadata'].items():
                            if isinstance(value, float):
                                print(f"     {key}: {value:.4f}")
                            else:
                                print(f"     {key}: {value}")
        print()


def compare_configs(audio_path: str):
    """
    å¯¹æ¯”é»˜è®¤é…ç½®å’Œå¹²å‡€è¯­éŸ³é…ç½®çš„æ£€æµ‹ç»“æœ
    
    Args:
        audio_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
    """
    print(f"\n{'=' * 70}")
    print(f"ğŸ“Š é…ç½®å¯¹æ¯”")
    print(f"{'=' * 70}\n")
    
    # åŠ è½½éŸ³é¢‘
    frames, sample_rate, duration = load_audio_file(audio_path)
    
    configs = [
        ("é»˜è®¤é…ç½®", Config(sample_rate=sample_rate)),
        ("å¹²å‡€è¯­éŸ³é…ç½®", Config(
            sample_rate=sample_rate,
            min_dropout_duration=0.20,
            min_distortion_duration=0.50,
            min_noise_duration=0.60,
            min_volume_duration=1.00
        ))
    ]
    
    results = []
    for name, config in configs:
        pipeline = DetectorPipeline(config)
        result = AnalysisResult()
        
        for event in pipeline.process(frames):
            result.add_event(event)
        
        result.finalize(duration)
        data = result.to_dict()
        
        counts = {
            'noise': data['noise']['count'],
            'dropout': data['dropout']['count'],
            'volume': data['volume_fluctuation']['count'],
            'distortion': data['voice_distortion']['count']
        }
        counts['total'] = sum(counts.values())
        
        results.append((name, counts))
    
    # æ˜¾ç¤ºå¯¹æ¯”è¡¨æ ¼
    print(f"{'é…ç½®':<15} {'å™ªå£°':>8} {'å¡é¡¿':>8} {'éŸ³é‡':>8} {'å¤±çœŸ':>8} {'æ€»è®¡':>8}")
    print(f"{'-' * 70}")
    
    for name, counts in results:
        print(f"{name:<15} {counts['noise']:>8} {counts['dropout']:>8} "
              f"{counts['volume']:>8} {counts['distortion']:>8} {counts['total']:>8}")
    
    # æ”¹å–„ç™¾åˆ†æ¯”
    if results[0][1]['total'] > 0:
        improvement = (1 - results[1][1]['total'] / results[0][1]['total']) * 100
        print(f"\nğŸ’¡ ä½¿ç”¨å¹²å‡€è¯­éŸ³é…ç½®å‡å°‘äº† {improvement:.1f}% çš„æ£€æµ‹é—®é¢˜\n")


def main():
    """ä¸»å‡½æ•°"""
    if len(sys.argv) < 2:
        print("ç”¨æ³•: python analyze_clean_speech.py <audio_file> [--compare]")
        print()
        print("ç¤ºä¾‹:")
        print("  python analyze_clean_speech.py sample.wav")
        print("  python analyze_clean_speech.py sample.wav --compare")
        return
    
    audio_path = sys.argv[1]
    
    if not os.path.exists(audio_path):
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {audio_path}")
        return
    
    # åŸºæœ¬åˆ†æ
    analyze_clean_speech(audio_path)
    
    # å¯¹æ¯”æ¨¡å¼
    if '--compare' in sys.argv:
        compare_configs(audio_path)


if __name__ == '__main__':
    main()
