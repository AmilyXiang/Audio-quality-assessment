# Voice Quality Analyzer - å®Œæ•´æ–‡æ¡£

## ğŸ“‹ ç›®å½•

1. [åŠŸèƒ½æ¦‚è¿°](#åŠŸèƒ½æ¦‚è¿°)
2. [å¿«é€Ÿå¼€å§‹](#å¿«é€Ÿå¼€å§‹)
3. [æ ¸å¿ƒåŠŸèƒ½](#æ ¸å¿ƒåŠŸèƒ½)
4. [é…ç½®è¯´æ˜](#é…ç½®è¯´æ˜)
5. [APIå‚è€ƒ](#apiå‚è€ƒ)
6. [æ•…éšœæ’æŸ¥](#æ•…éšœæ’æŸ¥)

---

## ğŸ¯ åŠŸèƒ½æ¦‚è¿°

è¯­éŸ³è´¨é‡è¯Šæ–­å·¥å…·ï¼Œä¸“æ³¨é€šè¯ä½“éªŒé—®é¢˜çš„æ£€æµ‹å’Œå®šä½ã€‚

### æ£€æµ‹èƒ½åŠ›

| é—®é¢˜ç±»å‹ | æ£€æµ‹æ–¹æ³• | è¾“å‡º |
|---------|---------|------|
| **å™ªå£°** | é›¶äº¤å‰ç‡(ZCR) + RMSèƒ½é‡ + Spectral Rolloff | å™ªå£°æ®µæ—¶é—´/å¼ºåº¦ |
| **å¡é¡¿** | æä½èƒ½é‡å¸§æ£€æµ‹ | é™éŸ³/ä¸¢åŒ…æ—¶é—´ç‚¹ |
| **éŸ³é‡æ³¢åŠ¨** | çŸ­æ—¶RMSå‰§çƒˆå˜åŒ– | å¼‚å¸¸æ³¢åŠ¨æ®µ |
| **å˜å£°/å¤±çœŸ** | é¢‘è°±ä¸­å¿ƒ/å¸¦å®½/æµé‡ + Peak-to-Peak | éŸ³è‰²çªå˜ç‚¹ |
| **å¯¹æ¯”åˆ†æ** | Cross-Correlation + DTWå¯¹é½ + å·®åˆ† | é€å¸§è´¨é‡å·® |

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. å®‰è£…

```bash
cd voice_quality_tool
pip install -r requirements.txt
```

**æ ¸å¿ƒä¾èµ–ï¼š**
- numpy >= 1.21.0ï¼ˆæ•°ç»„è®¡ç®—ï¼‰
- scipy >= 1.7.0ï¼ˆä¿¡å·å¤„ç†ï¼‰
- matplotlib >= 3.3.0ï¼ˆå¯è§†åŒ–ï¼‰
- librosa >= 0.9.0ï¼ˆMFCCæå–ï¼Œå¯é€‰ï¼‰
- dtw-python >= 1.3.0ï¼ˆåŠ¨æ€æ—¶é—´è§„æ•´ï¼Œå¯é€‰ï¼‰

### 2. åŸºç¡€åˆ†æ

```bash
# åˆ†æå•ä¸ªæ–‡ä»¶
python analyze_file.py audio.wav -o report.json

# å®æ—¶éº¦å…‹é£åˆ†æ
python analyze_mic.py 30  # å½•éŸ³30ç§’

# å¯¹æ¯”åˆ†æï¼ˆæµ‹è¯•éŸ³ vs åŸºå‡†éŸ³ï¼‰
python analyze_comparison.py test.wav baseline.wav -o comparison.json
```

### 3. è®¾å¤‡æ ¡å‡†

```bash
# ç”Ÿæˆè®¾å¤‡ä¸“ç”¨é…ç½®
python calibrate.py clean_speech.wav -o device.json

# ä½¿ç”¨è®¾å¤‡é…ç½®åˆ†æ
python analyze_file.py noisy_audio.wav -p device.json
```

---

## ğŸ”§ æ ¸å¿ƒåŠŸèƒ½

### åŠŸèƒ½1ï¼šç¦»çº¿åˆ†æ

**å‘½ä»¤ï¼š**
```bash
python analyze_file.py <audio_file> [options]
```

**é€‰é¡¹ï¼š**
- `-p, --profile <file>` - ä½¿ç”¨è®¾å¤‡é…ç½®æ–‡ä»¶
- `-o, --output <file>` - ä¿å­˜JSONæŠ¥å‘Š
- `--plot <file>` - ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨
- `-v, --verbose` - è¯¦ç»†è¾“å‡º

**ç¤ºä¾‹è¾“å‡ºï¼š**
```json
{
  "metadata": {
    "duration": 15.5,
    "sample_rate": 48000,
    "n_frames": 1550
  },
  "events": {
    "noise": [
      {"start": 2.3, "end": 3.7, "severity": "high"}
    ],
    "dropout": [
      {"start": 8.1, "end": 8.3, "severity": "medium"}
    ],
    "volume_fluctuation": [],
    "voice_distortion": [
      {"start": 12.5, "end": 13.0, "severity": "high"}
    ]
  }
}
```

### åŠŸèƒ½2ï¼šå®æ—¶ç›‘æµ‹

**å‘½ä»¤ï¼š**
```bash
python analyze_mic.py [duration]
```

**é€‚ç”¨åœºæ™¯ï¼š**
- é€šè¯è´¨é‡å®æ—¶ç›‘æ§
- è®¾å¤‡æ€§èƒ½æµ‹è¯•
- ç°åœºé—®é¢˜è¯Šæ–­

### åŠŸèƒ½3ï¼šå¯¹æ¯”åˆ†æï¼ˆNEWï¼‰

**æµç¨‹ï¼š**
1. **ç²—å¯¹é½** - Cross-Correlationæ£€æµ‹æ—¶é—´åç§»
2. **ç²¾å¯¹é½** - MFCC + DTWå¤„ç†è¯­é€Ÿå·®å¼‚ï¼ˆå¯é€‰ï¼‰
3. **å·®åˆ†è®¡ç®—** - é€å¸§"æµ‹è¯•å€¼ - åŸºå‡†å€¼"
4. **å¼‚å¸¸æ£€æµ‹** - è¯†åˆ«è¶…è¿‡é˜ˆå€¼(å‡å€¼Â±2Ïƒ)çš„å¸§

**å‘½ä»¤ï¼š**
```bash
python analyze_comparison.py test.wav baseline.wav -o result.json --plot
```

**è¾“å‡ºç»“æ„ï¼š**
```json
{
  "metadata": {...},
  "alignment": {
    "coarse_offset_sec": -0.5,
    "coarse_confidence": 0.85
  },
  "differential_statistics": {
    "rms_diff": {"mean": -0.002, "std": 0.015, ...},
    "zero_crossing_rate_diff": {...},
    "spectral_centroid_diff": {...}
  },
  "anomaly_detection": {
    "rms_diff": {
      "anomaly_count": 45,
      "anomaly_ratio": 0.03,
      "anomaly_segments": [...]
    }
  }
}
```

### åŠŸèƒ½4ï¼šè®¾å¤‡æ ¡å‡†

**ç›®çš„ï¼š** ä¸ºç‰¹å®šå½•éŸ³è®¾å¤‡ç”Ÿæˆè‡ªé€‚åº”é˜ˆå€¼

**å‘½ä»¤ï¼š**
```bash
python calibrate.py baseline.wav -o device.json
```

**ç”Ÿæˆå‚æ•°ï¼š**
- å™ªå£°åŸºçº¿ï¼ˆRMS, ZCRï¼‰
- è¯­éŸ³ç‰¹å¾èŒƒå›´ï¼ˆSpectral Centroid/Bandwidthï¼‰
- åŠ¨æ€é˜ˆå€¼ï¼ˆP95, æ ‡å‡†å·®ï¼‰

**ä½¿ç”¨æ ¡å‡†é…ç½®ï¼š**
```bash
python analyze_file.py test.wav -p device.json
```

---

## âš™ï¸ é…ç½®è¯´æ˜

### é¢„è®¾é…ç½®

**1. CLEAN_SPEECH_CONFIGï¼ˆæ¸…æ™°è¯­éŸ³ï¼‰**
```python
{
    'noise': {
        'zcr_threshold': 0.2,
        'rms_threshold': 0.02
    },
    'dropout': {
        'energy_threshold': 0.001,
        'min_duration': 0.1
    },
    'volume_fluctuation': {
        'rms_std_threshold': 0.15
    },
    'voice_distortion': {
        'spectral_centroid_change_threshold': 500,
        'spectral_flux_threshold': 0.5
    }
}
```

**2. NOISY_ENV_CONFIGï¼ˆå™ªå£°ç¯å¢ƒï¼‰**
- å™ªå£°é˜ˆå€¼æ”¾å®½ï¼ˆZCR: 0.35, RMS: 0.05ï¼‰
- å¡é¡¿æ£€æµ‹æ›´æ•æ„Ÿï¼ˆèƒ½é‡: 0.002ï¼‰

**3. MOBILE_CALL_CONFIGï¼ˆç§»åŠ¨é€šè¯ï¼‰**
- é€‚é…8kHzé‡‡æ ·ç‡
- æ£€æµ‹ç½‘ç»œä¸¢åŒ…ï¼ˆå¡é¡¿: 0.05sï¼‰

### æ‰‹åŠ¨è°ƒæ•´é˜ˆå€¼

```python
from analyzer.analyzer import Analyzer

custom_config = {
    'noise': {'zcr_threshold': 0.25},  # é™ä½å™ªå£°æ•æ„Ÿåº¦
    'dropout': {'energy_threshold': 0.0005}  # æé«˜å¡é¡¿æ•æ„Ÿåº¦
}

analyzer = Analyzer(config=custom_config)
result = analyzer.analyze_file('audio.wav')
```

---

## ğŸ“Š æ£€æµ‹åŸç†

### éŸ³é¢‘ç‰¹å¾ï¼ˆ9é¡¹ï¼‰

| ç‰¹å¾ | è®¡ç®—å…¬å¼ | ç‰©ç†æ„ä¹‰ | å…¸å‹èŒƒå›´ |
|------|---------|---------|---------|
| **RMS** | âˆš(Î£xÂ²/N) | èƒ½é‡/éŸ³é‡ | 0.01-0.5 |
| **Zero Crossing Rate** | ç¬¦å·å˜åŒ–/æ€»æ ·æœ¬ | å™ªå£°/é«˜é¢‘æˆåˆ† | 0.05-0.3 |
| **Spectral Centroid** | Î£(fÂ·A)/Î£A | é¢‘è°±é‡å¿ƒ/éŸ³è‰² | 500-3000 Hz |
| **Spectral Bandwidth** | âˆš(Î£(f-fc)Â²Â·A/Î£A) | é¢‘è°±åˆ†æ•£åº¦ | 500-2000 Hz |
| **Spectral Flux** | Î£\|(S[t]-S[t-1])\| | é¢‘è°±å˜åŒ–ç‡/æŠ–åŠ¨ | 0.01-0.5 |
| **Peak-to-Peak** | max(x) - min(x) | å‰Šæ³¢/å³°å€¼ | 0-2.0 |
| **Spectral Rolloff** | 85%èƒ½é‡ç‚¹é¢‘ç‡ | é£å™ª/é«˜é¢‘èƒ½é‡ | 2000-8000 Hz |
| **RMS P95** | RMSçš„95åˆ†ä½æ•° | ç¬æ€æ£€æµ‹ | 0.05-0.8 |
| **MFCC** | Melå€’è°±ç³»æ•° | éŸ³è‰²æŒ‡çº¹ï¼ˆ13/20ç»´ï¼‰ | - |

### æ£€æµ‹é€»è¾‘

**å™ªå£°æ£€æµ‹ï¼š**
```
IF (ZCR > é˜ˆå€¼ OR RMSå˜åŒ–ç‡ > é˜ˆå€¼ OR Spectral Rolloff > 3000 Hz)
   â†’ æ ‡è®°ä¸ºå™ªå£°æ®µ
```

**å¡é¡¿æ£€æµ‹ï¼š**
```
IF (RMS < èƒ½é‡é˜ˆå€¼ AND æŒç»­æ—¶é—´ > æœ€å°æŒç»­æ—¶é•¿)
   â†’ æ ‡è®°ä¸ºå¡é¡¿
```

**éŸ³é‡æ³¢åŠ¨ï¼š**
```
IF (RMSæ ‡å‡†å·® > é˜ˆå€¼ AND çŸ­æ—¶å˜åŒ– > 2å€æ ‡å‡†å·®)
   â†’ æ ‡è®°ä¸ºå¼‚å¸¸æ³¢åŠ¨
```

**å˜å£°/å¤±çœŸï¼š**
```
IF (|Spectral Centroidå˜åŒ–| > 500 Hz 
    OR Peak-to-Peak > 1.8 
    OR Spectral Flux > 0.5)
   â†’ æ ‡è®°ä¸ºå¤±çœŸ
```

---

## ğŸ”Œ APIå‚è€ƒ

### Pythoné›†æˆ

```python
from analyzer.analyzer import Analyzer
from analyzer.features import extract_features
from analyzer.frame import split_into_frames

# 1. åŸºç¡€åˆ†æ
analyzer = Analyzer()
result = analyzer.analyze_file('audio.wav')

for event in result.events['noise']:
    print(f"å™ªå£°: {event['start']:.2f}s - {event['end']:.2f}s")

# 2. è‡ªå®šä¹‰é…ç½®
config = {
    'frame_length': 2048,
    'hop_length': 512,
    'noise': {'zcr_threshold': 0.3}
}
analyzer = Analyzer(config=config)

# 3. å¯¹æ¯”åˆ†æ
from analyze_comparison import analyze_comparison

result = analyze_comparison(
    test_path='test.wav',
    baseline_path='baseline.wav',
    enable_alignment=True
)

# æŸ¥çœ‹å·®åˆ†ç»Ÿè®¡
stats = result['differential_statistics']
print(f"å¹³å‡RMSå·®: {stats['rms_diff']['mean']:.6f}")

# æŸ¥çœ‹å¼‚å¸¸æ®µ
anomalies = result['anomaly_detection']['rms_diff']
print(f"å¼‚å¸¸å¸§æ•°: {anomalies['anomaly_count']}")
```

### å‘½ä»¤è¡Œé›†æˆ

```bash
# Shellè„šæœ¬æ‰¹é‡åˆ†æ
for file in *.wav; do
    python analyze_file.py "$file" -o "${file%.wav}_report.json"
done

# ä½¿ç”¨è¿”å›ç åˆ¤æ–­è´¨é‡
python analyze_file.py audio.wav && echo "è´¨é‡æ­£å¸¸" || echo "æ£€æµ‹åˆ°é—®é¢˜"
```

---

## ğŸ› ï¸ æ•…éšœæ’æŸ¥

### å¸¸è§é—®é¢˜

**1. è¯¯æŠ¥å™ªå£°ï¼ˆå®‰é™ç¯å¢ƒè¢«æ ‡è®°ä¸ºå™ªå£°ï¼‰**
- **åŸå› ï¼š** è®¾å¤‡åº•å™ªé«˜äºé»˜è®¤é˜ˆå€¼
- **è§£å†³ï¼š** 
  ```bash
  python calibrate.py clean_baseline.wav -o device.json
  python analyze_file.py test.wav -p device.json
  ```

**2. æ¼æ£€å¡é¡¿ï¼ˆæ˜æ˜¾æ–­éŸ³æœªæ£€æµ‹ï¼‰**
- **åŸå› ï¼š** èƒ½é‡é˜ˆå€¼è¿‡ä½
- **è§£å†³ï¼š** è°ƒé«˜ `dropout.energy_threshold` æˆ–å‡å° `min_duration`
  ```python
  config = {'dropout': {'energy_threshold': 0.002, 'min_duration': 0.05}}
  ```

**3. å¯¹é½å¤±è´¥ï¼ˆåç§»æ£€æµ‹ä¸å‡†ï¼‰**
- **åŸå› ï¼š** éŸ³é¢‘å†…å®¹å·®å¼‚å¤§æˆ–ä¿¡å™ªæ¯”ä½
- **è§£å†³ï¼š** 
  - å¯ç”¨DTWç²¾å¯¹é½: å®‰è£… `librosa` å’Œ `dtw-python`
  - æ‰‹åŠ¨æŒ‡å®šåç§»: ä¿®æ”¹ `alignment.py` ä¸­çš„ `max_shift` å‚æ•°

**4. å†…å­˜æº¢å‡ºï¼ˆé•¿éŸ³é¢‘åˆ†æï¼‰**
- **åŸå› ï¼š** ä¸€æ¬¡æ€§åŠ è½½å…¨éƒ¨éŸ³é¢‘
- **è§£å†³ï¼š** åˆ†æ®µå¤„ç†æˆ–è°ƒæ•´å¸§å‚æ•°
  ```python
  config = {'frame_length': 1024, 'hop_length': 256}  # å‡å°‘å¸§æ•°
  ```

**5. librosa/dtwæœªå®‰è£…è­¦å‘Š**
- **å½±å“ï¼š** æ— æ³•ä½¿ç”¨MFCCå’ŒDTWç²¾å¯¹é½
- **è§£å†³ï¼š** 
  ```bash
  pip install librosa dtw-python
  ```

### è°ƒè¯•æŠ€å·§

**1. æŸ¥çœ‹ä¸­é—´ç‰¹å¾ï¼š**
```python
from analyzer.features import extract_features
from analyzer.frame import Frame

frames = split_into_frames(audio_data, sr)
for i, frame in enumerate(frames[:5]):
    features = extract_features(frame)
    print(f"å¸§{i}: RMS={features.rms:.4f}, ZCR={features.zero_crossing_rate:.4f}")
```

**2. å¯è§†åŒ–ç‰¹å¾æ—¶é—´åºåˆ—ï¼š**
```bash
python analyze_comparison.py test.wav baseline.wav --plot comparison.png
```

**3. å¯ç”¨è¯¦ç»†æ—¥å¿—ï¼š**
```bash
python analyze_file.py audio.wav -v
```

---

## ğŸ“š è¿›é˜¶ä¸»é¢˜

### æ‰¹é‡åˆ†æ

```python
import glob
import json
from analyzer.analyzer import Analyzer

analyzer = Analyzer()
results = {}

for audio_path in glob.glob('audio_samples/*.wav'):
    result = analyzer.analyze_file(audio_path)
    results[audio_path] = {
        'noise_count': len(result.events['noise']),
        'dropout_count': len(result.events['dropout']),
        'quality_score': result.summary.get('quality_score', 0)
    }

with open('batch_report.json', 'w') as f:
    json.dump(results, f, indent=2)
```

### å®æ—¶æµå¤„ç†

```python
import pyaudio
from analyzer.analyzer import Analyzer
from analyzer.frame import Frame

analyzer = Analyzer()
p = pyaudio.PyAudio()

def callback(in_data, frame_count, time_info, status):
    audio = np.frombuffer(in_data, dtype=np.int16).astype(np.float32) / 32768.0
    frame = Frame(audio, 0, len(audio), 16000)
    
    features = extract_features(frame)
    if features.zero_crossing_rate > 0.3:
        print(f"[è­¦å‘Š] æ£€æµ‹åˆ°å™ªå£°: ZCR={features.zero_crossing_rate:.3f}")
    
    return (in_data, pyaudio.paContinue)

stream = p.open(format=pyaudio.paInt16, channels=1, rate=16000,
                input=True, stream_callback=callback)
stream.start_stream()
```

### è‡ªå®šä¹‰æ£€æµ‹å™¨

```python
from analyzer.detectors.base import BaseDetector

class CustomDetector(BaseDetector):
    def __init__(self, config):
        super().__init__(config)
        self.threshold = config.get('threshold', 0.5)
    
    def detect(self, features, frame_index, time):
        if features.rms > self.threshold:
            return {
                'start': time,
                'end': time + 0.01,
                'severity': 'high',
                'value': features.rms
            }
        return None
```

---

## ğŸ“– å‚è€ƒèµ„æ–™

**æ ¸å¿ƒæ–‡æ¡£ï¼š**
- `docs/DETECTION_PRINCIPLES.md` - æ£€æµ‹åŸç†è¯¦è§£
- `docs/CLEAN_SPEECH_CONFIG.md` - é…ç½®é¢„è®¾è¯´æ˜

**ç¤ºä¾‹ä»£ç ï¼š**
- `examples/demo_dropout_detection.py` - å¡é¡¿æ£€æµ‹ç¤ºä¾‹
- `examples/analyze_clean_speech.py` - æ¸…æ™°è¯­éŸ³åˆ†æ

**æ¶æ„è®¾è®¡ï¼š**
- æ£€æµ‹å™¨ä½äº `analyzer/detectors/` ç›®å½•
- ç‰¹å¾æå– `analyzer/features.py`
- å¸§å¤„ç† `analyzer/frame.py`

---

## ğŸ“ æ”¯æŒ

é‡åˆ°é—®é¢˜è¯·æŸ¥é˜…ï¼š
1. æœ¬æ–‡æ¡£çš„[æ•…éšœæ’æŸ¥](#æ•…éšœæ’æŸ¥)ç« èŠ‚
2. `docs/DETECTION_PRINCIPLES.md` ä¸­çš„åŸç†è¯´æ˜
3. è¿è¡Œ `python <script>.py --help` æŸ¥çœ‹å‘½ä»¤å¸®åŠ©

---

**ç‰ˆæœ¬ï¼š** 2.0 (å«å¯¹é½å¯¹æ¯”åŠŸèƒ½)  
**æ›´æ–°æ—¥æœŸï¼š** 2026-02-06
