#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¯¹æ¯”åˆ†æå·¥å…· - åŸºäºå¯¹é½çš„é€å¸§å·®åˆ†

ç”¨æ³•ï¼š
    python analyze_comparison.py test.wav baseline.wav -o comparison.json
    python analyze_comparison.py test.wav baseline.wav --plot
"""

import sys
import json
import argparse
import numpy as np
from pathlib import Path
from scipy.io import wavfile
from typing import Dict, List

# æ·»åŠ è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent))

from analyzer.alignment import align_audio_precise
from analyzer.features import extract_features
from analyzer.frame import Frame


def load_audio(path: str) -> tuple:
    """åŠ è½½éŸ³é¢‘æ–‡ä»¶å¹¶å½’ä¸€åŒ–"""
    sr, data = wavfile.read(path)
    if len(data.shape) > 1:
        data = data[:, 0]
    data = data.astype(float)
    if data.max() > 1.0 or data.min() < -1.0:
        data = data / (2 ** 15)
    return sr, data


def frame_generator_aligned(data: np.ndarray, sr: int, frame_size: int, hop_size: int):
    """ç”Ÿæˆå¸§åºåˆ—ï¼ˆä¸analyzer.frame_generatorå…¼å®¹ï¼‰"""
    from analyzer.frame import Frame
    num_frames = (len(data) - frame_size) // hop_size + 1
    for i in range(num_frames):
        start_idx = i * hop_size
        end_idx = start_idx + frame_size
        if end_idx <= len(data):
            samples = data[start_idx:end_idx]
            start_time = start_idx / sr
            end_time = end_idx / sr
            yield Frame(samples, sr, start_time, end_time)


def compute_frame_diff(test_features: Dict, baseline_features: Dict) -> Dict:
    """
    è®¡ç®—å•å¸§çš„å·®åˆ†ç‰¹å¾
    
    Args:
        test_features: æµ‹è¯•éŸ³é¢‘çš„å¸§ç‰¹å¾
        baseline_features: åŸºå‡†éŸ³é¢‘çš„å¸§ç‰¹å¾
        
    Returns:
        å·®åˆ†ç‰¹å¾å­—å…¸ï¼ˆå®é™…å€¼ - baselineå€¼ï¼‰
    """
    diff = {}
    
    # æ ¸å¿ƒç‰¹å¾å·®åˆ†
    for key in ['rms', 'zero_crossing_rate', 'spectral_centroid', 'spectral_bandwidth', 'spectral_flux']:
        if key in test_features and key in baseline_features:
            test_val = test_features[key]
            base_val = baseline_features[key]
            diff[f'{key}_diff'] = test_val - base_val
            diff[f'{key}_ratio'] = test_val / (base_val + 1e-10)
            diff[f'{key}_test'] = test_val
            diff[f'{key}_baseline'] = base_val
    
    # ç¬¬1é˜¶æ®µç‰¹å¾å·®åˆ†
    for key in ['peak_to_peak', 'spectral_rolloff', 'rms_percentile_95']:
        if key in test_features and key in baseline_features:
            test_val = test_features[key]
            base_val = baseline_features[key]
            diff[f'{key}_diff'] = test_val - base_val
            diff[f'{key}_test'] = test_val
            diff[f'{key}_baseline'] = base_val
    
    return diff


def analyze_comparison(test_path: str, baseline_path: str, 
                       enable_alignment: bool = True,
                       frame_duration: float = 0.025,
                       hop_duration: float = 0.010) -> Dict:
    """
    å¯¹æ¯”åˆ†æä¸¤ä¸ªéŸ³é¢‘æ–‡ä»¶
    
    Args:
        test_path: æµ‹è¯•éŸ³é¢‘è·¯å¾„
        baseline_path: åŸºå‡†éŸ³é¢‘è·¯å¾„
        enable_alignment: æ˜¯å¦å¯ç”¨ç²¾ç¡®å¯¹é½
        frame_duration: å¸§æ—¶é•¿ï¼ˆç§’ï¼‰
        hop_duration: è·³è·ƒæ—¶é•¿ï¼ˆç§’ï¼‰
        
    Returns:
        å¯¹æ¯”åˆ†æç»“æœå­—å…¸
    """
    print("\n" + "=" * 70)
    print("å¯¹æ¯”åˆ†æ - åŸºäºå¯¹é½çš„é€å¸§å·®åˆ†".center(70))
    print("=" * 70)
    
    # 1. åŠ è½½éŸ³é¢‘
    print(f"\n[*] åŠ è½½éŸ³é¢‘æ–‡ä»¶...")
    sr_test, data_test = load_audio(test_path)
    sr_base, data_base = load_audio(baseline_path)
    
    print(f"   æµ‹è¯•: {Path(test_path).name} ({len(data_test)/sr_test:.2f}s @ {sr_test}Hz)")
    print(f"   åŸºå‡†: {Path(baseline_path).name} ({len(data_base)/sr_base:.2f}s @ {sr_base}Hz)")
    
    # 2. å¯¹é½éŸ³é¢‘
    alignment_info = None
    if enable_alignment:
        print(f"\n[*] éŸ³é¢‘å¯¹é½...")
        # ç»Ÿä¸€é‡‡æ ·ç‡
        target_sr = max(sr_test, sr_base)
        if sr_test != target_sr:
            from scipy import signal as scipy_signal
            data_test = scipy_signal.resample(data_test, int(len(data_test) * target_sr / sr_test))
            sr_test = target_sr
        if sr_base != target_sr:
            from scipy import signal as scipy_signal
            data_base = scipy_signal.resample(data_base, int(len(data_base) * target_sr / sr_base))
            sr_base = target_sr
        
        # ç²¾ç¡®å¯¹é½
        result = align_audio_precise(data_base, data_test, sr_test, 
                                     enable_coarse=True, enable_fine=False)
        data_base = result['aligned_reference']
        data_test = result['aligned_test']
        alignment_info = {
            'coarse_offset_sec': result['coarse_offset'] / sr_test,
            'coarse_confidence': result['coarse_confidence'],
            'quality': result['alignment_quality']
        }
        print(f"   [OK] å¯¹é½å®Œæˆ: åç§»={alignment_info['coarse_offset_sec']:.3f}s, ç½®ä¿¡åº¦={alignment_info['coarse_confidence']:.2%}")
    else:
        # ç®€å•è£å‰ª
        min_len = min(len(data_test), len(data_base))
        data_test = data_test[:min_len]
        data_base = data_base[:min_len]
    
    # 3. é€å¸§ç‰¹å¾æå–å’Œå·®åˆ†
    print(f"\n[*] é€å¸§å·®åˆ†è®¡ç®—...")
    frame_size = int(sr_test * frame_duration)
    hop_size = int(sr_test * hop_duration)
    
    frames_test = list(frame_generator_aligned(data_test, sr_test, frame_size, hop_size))
    frames_base = list(frame_generator_aligned(data_base, sr_test, frame_size, hop_size))
    
    n_frames = min(len(frames_test), len(frames_base))
    print(f"   æ€»å¸§æ•°: {n_frames} å¸§ ({n_frames * hop_duration:.2f}s)")
    
    frame_diffs = []
    prev_test_frame = None
    prev_base_frame = None
    
    for i in range(n_frames):
        # æå–ç‰¹å¾
        test_features = extract_features(frames_test[i], prev_test_frame)
        base_features = extract_features(frames_base[i], prev_base_frame)
        
        # è®¡ç®—å·®åˆ†
        diff = compute_frame_diff(test_features, base_features)
        diff['time'] = frames_test[i].start_time
        diff['frame_index'] = i
        
        frame_diffs.append(diff)
        
        prev_test_frame = frames_test[i]
        prev_base_frame = frames_base[i]
        
        if (i + 1) % 100 == 0:
            print(f"   å¤„ç†è¿›åº¦: {i+1}/{n_frames} ({(i+1)/n_frames*100:.1f}%)", end='\r')
    
    print(f"\n   [OK] å®Œæˆ {len(frame_diffs)} å¸§çš„å·®åˆ†è®¡ç®—")
    
    # 4. ç»Ÿè®¡æ±‡æ€»
    print(f"\n[*] å·®åˆ†ç»Ÿè®¡...")
    stats = compute_diff_statistics(frame_diffs)
    
    # 5. å¼‚å¸¸æ£€æµ‹
    print(f"\n[*] å¼‚å¸¸æ£€æµ‹...")
    anomalies = detect_anomalies(frame_diffs, stats)
    
    # 6. è¾“å‡ºç»“æœï¼ˆç»“æ„åŒ–æŠ¥å‘Šï¼‰
    result = {
        'metadata': {
            'test_file': Path(test_path).name,
            'baseline_file': Path(baseline_path).name,
            'test_duration': len(data_test) / sr_test,
            'baseline_duration': len(data_base) / sr_base,
            'aligned_duration': n_frames * hop_duration,
            'sample_rate': sr_test,
            'frame_length_ms': frame_duration * 1000,
            'frame_shift_ms': hop_duration * 1000,
            'n_frames': n_frames
        },
        'alignment': alignment_info if alignment_info else {'method': 'simple_trim'},
        'differential_statistics': stats,
        'anomaly_detection': anomalies,
        'frame_by_frame_diff': frame_diffs
    }
    
    print_summary(stats, anomalies)
    
    return result


def compute_diff_statistics(frame_diffs: List[Dict]) -> Dict:
    """è®¡ç®—å·®åˆ†ç»Ÿè®¡é‡"""
    stats = {}
    
    # æå–å·®åˆ†åºåˆ—
    diff_keys = [k for k in frame_diffs[0].keys() if k.endswith('_diff')]
    
    for key in diff_keys:
        values = [f[key] for f in frame_diffs if key in f]
        if values:
            values_arr = np.array(values)
            stats[key] = {
                'mean': float(np.mean(values_arr)),
                'std': float(np.std(values_arr)),
                'min': float(np.min(values_arr)),
                'max': float(np.max(values_arr)),
                'median': float(np.median(values_arr)),
                'p95': float(np.percentile(values_arr, 95))
            }
    
    return stats


def detect_anomalies(frame_diffs: List[Dict], stats: Dict, threshold_sigma: float = 2.0) -> Dict:
    """
    æ£€æµ‹å¼‚å¸¸å¸§ - å·®åˆ†è¶…è¿‡é˜ˆå€¼çš„å¸§
    
    Args:
        frame_diffs: å¸§å·®åˆ†åˆ—è¡¨
        stats: ç»Ÿè®¡ä¿¡æ¯
        threshold_sigma: é˜ˆå€¼å€æ•°ï¼ˆå‡å€¼ Â± threshold_sigma * æ ‡å‡†å·®ï¼‰
    
    Returns:
        anomalies: {
            'feature_name': {
                'threshold': float,
                'anomaly_count': int,
                'anomaly_ratio': float,
                'anomaly_frames': [int],
                'anomaly_segments': [{'start_frame', 'end_frame', 'start_time', 'end_time', 'duration'}]
            }
        }
    """
    anomalies = {}
    
    # å¯¹æ¯ä¸ªå·®åˆ†æŒ‡æ ‡è¿›è¡Œå¼‚å¸¸æ£€æµ‹
    diff_keys = [k for k in stats.keys() if k.endswith('_diff')]
    
    for key in diff_keys:
        mean = stats[key]['mean']
        std = stats[key]['std']
        threshold = abs(mean) + threshold_sigma * std
        
        # æ‰¾å‡ºå¼‚å¸¸å¸§ï¼ˆç»å¯¹å€¼è¶…è¿‡é˜ˆå€¼ï¼‰
        anomaly_frames = []
        for i, frame in enumerate(frame_diffs):
            if key in frame:
                value = abs(frame[key])
                if value > threshold:
                    anomaly_frames.append(i)
        
        # åˆå¹¶è¿ç»­å¼‚å¸¸å¸§ä¸ºæ®µ
        anomaly_segments = []
        if anomaly_frames:
            start = anomaly_frames[0]
            end = anomaly_frames[0]
            
            for frame_idx in anomaly_frames[1:]:
                if frame_idx == end + 1:
                    end = frame_idx
                else:
                    # ä¿å­˜å½“å‰æ®µ
                    segment = {
                        'start_frame': int(start),
                        'end_frame': int(end),
                        'start_time': round(frame_diffs[start]['time'], 2),
                        'end_time': round(frame_diffs[end]['time'], 2),
                        'duration': round(frame_diffs[end]['time'] - frame_diffs[start]['time'], 2)
                    }
                    anomaly_segments.append(segment)
                    start = frame_idx
                    end = frame_idx
            
            # æœ€åä¸€ä¸ªæ®µ
            segment = {
                'start_frame': int(start),
                'end_frame': int(end),
                'start_time': round(frame_diffs[start]['time'], 2),
                'end_time': round(frame_diffs[end]['time'], 2),
                'duration': round(frame_diffs[end]['time'] - frame_diffs[start]['time'], 2)
            }
            anomaly_segments.append(segment)
        
        anomalies[key] = {
            'threshold': float(threshold),
            'anomaly_count': len(anomaly_frames),
            'anomaly_ratio': len(anomaly_frames) / len(frame_diffs) if frame_diffs else 0.0,
            'anomaly_frames': anomaly_frames[:100],  # æœ€å¤šä¿å­˜å‰100ä¸ª
            'anomaly_segments': anomaly_segments
        }
    
    return anomalies


def print_summary(stats: Dict, anomalies: Dict):
    """æ‰“å°ç»Ÿè®¡æ‘˜è¦"""
    print("\n" + "=" * 70)
    print("å·®åˆ†ç»Ÿè®¡æ‘˜è¦".center(70))
    print("=" * 70)
    
    # RMSå·®åˆ†
    if 'rms_diff' in stats:
        s = stats['rms_diff']
        print(f"\n[RMSèƒ½é‡å·®åˆ†]:")
        print(f"   å¹³å‡å·®: {s['mean']:+.6f}  (æ­£å€¼=æµ‹è¯•éŸ³é‡é«˜äºåŸºå‡†)")
        print(f"   æ ‡å‡†å·®: {s['std']:.6f}")
        print(f"   èŒƒå›´: {s['min']:+.6f} ~ {s['max']:+.6f}")
        if 'rms_diff' in anomalies:
            print(f"   å¼‚å¸¸å¸§: {anomalies['rms_diff']['anomaly_count']} ({anomalies['rms_diff']['anomaly_ratio']:.1%})")
    
    # å™ªå£°å·®åˆ†ï¼ˆè¿‡é›¶ç‡ï¼‰
    if 'zero_crossing_rate_diff' in stats:
        s = stats['zero_crossing_rate_diff']
        print(f"\n[è¿‡é›¶ç‡å·®åˆ†] (å™ªå£°æŒ‡æ ‡):")
        print(f"   å¹³å‡å·®: {s['mean']:+.6f}  (æ­£å€¼=æµ‹è¯•å™ªå£°é«˜äºåŸºå‡†)")
        print(f"   æ ‡å‡†å·®: {s['std']:.6f}")
        print(f"   èŒƒå›´: {s['min']:+.6f} ~ {s['max']:+.6f}")
        if 'zero_crossing_rate_diff' in anomalies:
            print(f"   å¼‚å¸¸å¸§: {anomalies['zero_crossing_rate_diff']['anomaly_count']} ({anomalies['zero_crossing_rate_diff']['anomaly_ratio']:.1%})")
    
    # é¢‘è°±ä¸­å¿ƒå·®åˆ†
    if 'spectral_centroid_diff' in stats:
        s = stats['spectral_centroid_diff']
        print(f"\n[é¢‘è°±ä¸­å¿ƒå·®åˆ†] (éŸ³è‰²å˜åŒ–):")
        print(f"   å¹³å‡å·®: {s['mean']:+.1f} Hz")
        print(f"   æ ‡å‡†å·®: {s['std']:.1f} Hz")
        print(f"   èŒƒå›´: {s['min']:+.1f} ~ {s['max']:+.1f} Hz")
        if 'spectral_centroid_diff' in anomalies:
            print(f"   å¼‚å¸¸å¸§: {anomalies['spectral_centroid_diff']['anomaly_count']} ({anomalies['spectral_centroid_diff']['anomaly_ratio']:.1%})")
    
    # é¢‘è°±é€šé‡å·®åˆ†ï¼ˆæŠ–åŠ¨ï¼‰
    if 'spectral_flux_diff' in stats:
        s = stats['spectral_flux_diff']
        print(f"\n[é¢‘è°±é€šé‡å·®åˆ†] (æŠ–åŠ¨/ä¸ç¨³å®šæ€§):")
        print(f"   å¹³å‡å·®: {s['mean']:+.6f}  (æ­£å€¼=æµ‹è¯•æ›´æŠ–)")
        print(f"   æ ‡å‡†å·®: {s['std']:.6f}")
        print(f"   èŒƒå›´: {s['min']:+.6f} ~ {s['max']:+.6f}")
        if 'spectral_flux_diff' in anomalies:
            print(f"   å¼‚å¸¸å¸§: {anomalies['spectral_flux_diff']['anomaly_count']} ({anomalies['spectral_flux_diff']['anomaly_ratio']:.1%})")
    
    print("\n" + "=" * 70)


def main():
    parser = argparse.ArgumentParser(
        description='å¯¹æ¯”åˆ†æå·¥å…· - åŸºäºå¯¹é½çš„é€å¸§å·®åˆ†',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  python analyze_comparison.py test.wav baseline.wav -o result.json
  python analyze_comparison.py test.wav baseline.wav --no-align  # ä¸å¯¹é½
  python analyze_comparison.py test.wav baseline.wav --plot  # ç”Ÿæˆå·®åˆ†å›¾è¡¨
        """
    )
    
    parser.add_argument('test_audio', help='æµ‹è¯•éŸ³é¢‘æ–‡ä»¶')
    parser.add_argument('baseline_audio', help='åŸºå‡†éŸ³é¢‘æ–‡ä»¶')
    parser.add_argument('-o', '--output', help='è¾“å‡ºJSONæ–‡ä»¶è·¯å¾„')
    parser.add_argument('--no-align', action='store_true', help='ç¦ç”¨ç²¾ç¡®å¯¹é½')
    parser.add_argument('--plot', action='store_true', help='ç”Ÿæˆå·®åˆ†å¯è§†åŒ–å›¾è¡¨')
    
    args = parser.parse_args()
    
    # æ‰§è¡Œå¯¹æ¯”åˆ†æ
    result = analyze_comparison(
        args.test_audio,
        args.baseline_audio,
        enable_alignment=not args.no_align
    )
    
    # ä¿å­˜ç»“æœ
    if args.output:
        with open(args.output, 'w', encoding='utf-8') as f:
            json.dump(result, f, ensure_ascii=False, indent=2)
        print(f"\nğŸ’¾ ç»“æœå·²ä¿å­˜: {args.output}")
    
    # ç”Ÿæˆå›¾è¡¨
    if args.plot:
        plot_path = args.output.replace('.json', '_plot.png') if args.output else 'comparison_plot.png'
        try:
            from generate_comparison_plot import plot_comparison_result
            plot_comparison_result(result, plot_path)
            print(f"ğŸ“Š å·®åˆ†å›¾è¡¨å·²ä¿å­˜: {plot_path}")
        except ImportError:
            print("âš ï¸  ç»˜å›¾æ¨¡å—æœªæ‰¾åˆ°ï¼Œè·³è¿‡å¯è§†åŒ–")


if __name__ == '__main__':
    main()
